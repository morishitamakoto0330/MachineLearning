{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LeNet Class\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers\n",
    "from chainer import Variable\n",
    "from chainer import cuda\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class LeNet(chainer.Chain):\n",
    "    def __init__(self, num_class, train=True):\n",
    "        super(LeNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1=L.Convolution2D(None, 6, 5, stride=1)\n",
    "            self.conv2=L.Convolution2D(None, 16, 5, stride=1)\n",
    "            self.conv3=L.Convolution2D(None, 120, 5, stride=1)\n",
    "            self.fc4=L.Linear(None, 84)\n",
    "            self.fc5=L.Linear(None, num_class)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        h1 = F.max_pooling_2d(F.local_response_normalization(\n",
    "            F.sigmoid(self.conv1(x))), 2, stride=2)\n",
    "        h2 = F.max_pooling_2d(F.local_response_normalization(\n",
    "            F.sigmoid(self.conv2(h1))), 2, stride=2)\n",
    "        h3 = F.sigmoid(self.conv3(h2))\n",
    "        h4 = F.sigmoid(self.fc4(h3))\n",
    "        h5 = self.fc5(h4)\n",
    "        \n",
    "        return h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST data set\n",
    "\n",
    "train, test = chainer.datasets.get_mnist()\n",
    "_xs, ts = train._datasets\n",
    "_txs, tts = test._datasets\n",
    "\n",
    "size = 10000\n",
    "_xs = _xs[:size]\n",
    "ts = ts[:size]\n",
    "_txs = _txs[:size]\n",
    "_txs = _txs[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# padding (60000, 784) -> (60000, 1, 28, 28) -> (60000, 1, 32, 32)\n",
    "\n",
    "_v0 = np.row_stack((np.zeros(28), np.zeros(28)))\n",
    "v0 = np.array(_v0)\n",
    "_h0 = np.column_stack((np.zeros(32), np.zeros(32)))\n",
    "h0 = np.array(_h0)\n",
    "\n",
    "def padding(x):\n",
    "    tmp1 = np.vstack((x, v0))\n",
    "    tmp2 = np.vstack((v0, tmp1))\n",
    "    _tmp1 = np.hstack((tmp2, h0))\n",
    "    _tmp2 = np.hstack((h0, _tmp1))\n",
    "    return _tmp2\n",
    "\n",
    "xs_list = []\n",
    "for i in range(len(_xs)):\n",
    "    x = np.reshape(_xs[i], (28, 28))\n",
    "    pad_x = padding(x)\n",
    "    xs_list.append(pad_x[np.newaxis, :, :])\n",
    "txs_list = []\n",
    "for i in range(len(_txs)):\n",
    "    tx = np.reshape(_txs[i], (28, 28))\n",
    "    pad_tx = padding(tx)\n",
    "    txs_list.append(pad_tx[np.newaxis, :, :])\n",
    "    \n",
    "xs = np.array(xs_list, dtype=np.float32)\n",
    "txs = np.array(txs_list, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# method\n",
    "\n",
    "def check_accuracy(model, xs, ts, batchsize):\n",
    "    loss = 0\n",
    "    num_cors = 0\n",
    "    for i in range(0, len(xs), batchsize):\n",
    "        x = xs[i:i + batchsize]\n",
    "        t = ts[i:i + batchsize]\n",
    "        \n",
    "        #var_xs = Variable(cuda.to_gpu(x))\n",
    "        var_xs = Variable(x)\n",
    "        t = Variable(np.array(t, \"i\"))\n",
    "        ys = model(var_xs)\n",
    "    \n",
    "        loss += F.softmax_cross_entropy(ys, t)\n",
    "        ys = np.argmax(ys.data, axis=1)\n",
    "        #_t = cuda.to_gpu(np.array(cuda.to_cpu(t.data), dtype=np.float32))\n",
    "        _t = np.array(t.data, dtype=np.float32)\n",
    "        if i == 0:\n",
    "            print(_t)\n",
    "            print(ys)\n",
    "        cors = (ys == _t)\n",
    "        num_cors += sum(cors)\n",
    "    accuracy = num_cors / ts.shape[0]\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "1: weight=variable W([[[[-0.04421652  0.04789857  0.13680373  0.18192339 -0.16801828]\n",
      "              [-0.12237698 -0.01170773 -0.00318625 -0.04184784 -0.05611006]\n",
      "              [-0.02500872  0.13513084 -0.1720708  -0.26352841 -0.02425263]\n",
      "              [ 0.08136676 -0.04669612  0.12748228  0.12991345 -0.14078689]\n",
      "              [-0.18675731  0.10420867 -0.14834806 -0.16371301  0.59928948]]]\n",
      "\n",
      "\n",
      "            [[[-0.02214537  0.33359861 -0.01046258  0.07998809 -0.02100551]\n",
      "              [ 0.3376655  -0.12234784  0.15783331  0.54421079  0.29253486]\n",
      "              [-0.22815999 -0.03082688  0.25600138  0.04009216  0.50543547]\n",
      "              [ 0.00414038 -0.10721585  0.36767256  0.00395125  0.53157425]\n",
      "              [-0.01552834 -0.12347528 -0.04866714  0.44614357  0.27518132]]]\n",
      "\n",
      "\n",
      "            [[[ 0.20732254  0.00856662 -0.22419782  0.08861777 -0.54274768]\n",
      "              [-0.04923407 -0.08085664 -0.07715793  0.13159259 -0.45899004]\n",
      "              [ 0.24458645 -0.04428369 -0.25122353  0.10396598 -0.07259381]\n",
      "              [-0.23737827  0.04870647 -0.18910104 -0.35319057  0.14336601]\n",
      "              [ 0.04464544  0.14999762 -0.18013112 -0.13972148 -0.1433275 ]]]\n",
      "\n",
      "\n",
      "            [[[-0.14820774 -0.38313526  0.17470384 -0.20922248  0.35317644]\n",
      "              [ 0.0099152  -0.18898883 -0.07356562  0.08349576  0.13228568]\n",
      "              [ 0.02151465 -0.27367786  0.31907618  0.18350992  0.14428996]\n",
      "              [ 0.01148946  0.01415202 -0.29986244 -0.34607774  0.38426307]\n",
      "              [-0.19042623 -0.33975559 -0.12568076 -0.15593089  0.3542169 ]]]\n",
      "\n",
      "\n",
      "            [[[-0.00143969  0.07936391  0.16723028 -0.11320113 -0.1363382 ]\n",
      "              [ 0.15027383  0.16908668  0.10347479  0.02135823  0.03368074]\n",
      "              [ 0.34567875  0.0429186   0.01418209  0.12804528  0.33320257]\n",
      "              [-0.05027549 -0.25845906  0.22188184  0.14372934 -0.02078891]\n",
      "              [ 0.12750684  0.19827367 -0.03859567  0.19018939  0.11894291]]]\n",
      "\n",
      "\n",
      "            [[[ 0.30371365 -0.00813189  0.03713083  0.21878977  0.01820417]\n",
      "              [ 0.30433431 -0.01600148  0.00716701 -0.15609598 -0.00305441]\n",
      "              [ 0.29913622  0.20568933  0.26348847 -0.09245031 -0.00603169]\n",
      "              [-0.20527989  0.48035336 -0.16063188  0.03810142  0.24773376]\n",
      "              [ 0.0053974   0.09635875 -0.16677114  0.21883324  0.23867811]]]]), bias=variable b([-0.01341266 -0.06488093 -0.02267183 -0.015999   -0.01087715\n",
      "            -0.03041882])\n",
      "Epoch 1 loss(train) = variable(230.33197021484375), accuracy(train) = 0.1032, accuracy(test) = 0.101\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 3 3 3 6 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 3 3 3 3 3 3 3 3 3]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 3 3 3 3 3 3 3 3 3 3 3 6 3 3 3\n",
      " 3 3 3 3 3 3 6 3 3 3 3 3 3 3 3 3 3 6 3 3 3 3 3 3 3 3 3 3 3 3 6 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 6 3 3 6 3 3 3 3 3 3 6 3]\n",
      "1: weight=variable W([[[[-0.11325236 -0.02926416  0.05288928  0.08853575 -0.28079161]\n",
      "              [-0.21039042 -0.10822201 -0.10093454 -0.14949039 -0.17742795]\n",
      "              [-0.11887897  0.03609226 -0.272742   -0.37862852 -0.14283361]\n",
      "              [-0.01541107 -0.14718369  0.02333155  0.0184618  -0.24712054]\n",
      "              [-0.28006732  0.00197834 -0.25463659 -0.27035519  0.50977612]]]\n",
      "\n",
      "\n",
      "            [[[-0.04293642  0.40306151  0.12585025  0.23499513  0.13314915]\n",
      "              [ 0.32047284 -0.0147699   0.31241244  0.70775831  0.45118362]\n",
      "              [-0.26724809  0.07915978  0.41620213  0.20330855  0.66160941]\n",
      "              [-0.03771362  0.00365207  0.52925372  0.16771774  0.68656939]\n",
      "              [-0.07244431 -0.02122497  0.10364742  0.60381705  0.41841719]]]\n",
      "\n",
      "\n",
      "            [[[ 0.22110869 -0.1444969  -0.40668541 -0.09731001 -0.73662478]\n",
      "              [-0.08876584 -0.24814403 -0.26522145 -0.05777213 -0.65943229]\n",
      "              [ 0.18573239 -0.21808259 -0.44407833 -0.08695017 -0.26990297]\n",
      "              [-0.33514878 -0.12583563 -0.38225669 -0.54618526 -0.04818321]\n",
      "              [-0.05232804 -0.02411906 -0.37841499 -0.33510935 -0.3317194 ]]]\n",
      "\n",
      "\n",
      "            [[[-0.32887048 -0.54786819  0.06767968 -0.13970496  0.51331431]\n",
      "              [-0.17537048 -0.36358726 -0.2008653   0.14099145  0.29306933]\n",
      "              [-0.16254592 -0.45144254  0.18474367  0.25143838  0.30555579]\n",
      "              [-0.17077613 -0.16573445 -0.44476372 -0.23086146  0.54762208]\n",
      "              [-0.37532163 -0.51881045 -0.25419757 -0.0450782   0.51008397]]]\n",
      "\n",
      "\n",
      "            [[[ 0.12777112  0.22906967  0.32207328  0.03982496 -0.02674824]\n",
      "              [ 0.30018666  0.32801214  0.26739499  0.18207741  0.16939187]\n",
      "              [ 0.50434375  0.21127267  0.18324861  0.28810152  0.47353995]\n",
      "              [ 0.11700718 -0.08381674  0.38869786  0.30100313  0.11612894]\n",
      "              [ 0.28844017  0.36490741  0.12300538  0.33834764  0.24064547]]]\n",
      "\n",
      "\n",
      "            [[[ 0.43522725  0.14405625  0.18856786  0.35206521  0.04154296]\n",
      "              [ 0.4599061   0.15408447  0.17978863  0.00875198  0.08560371]\n",
      "              [ 0.46304932  0.37733838  0.43845159  0.07398448  0.11009862]\n",
      "              [-0.04067779  0.64838111  0.00918654  0.20135902  0.35956657]\n",
      "              [ 0.16328117  0.25708205 -0.00357773  0.36592758  0.3168025 ]]]]), bias=variable b([ 0.0353505  -0.25274807  0.12311805  0.00829707 -0.18766777\n",
      "            -0.18911262])\n",
      "Epoch 2 loss(train) = variable(227.2071533203125), accuracy(train) = 0.1539, accuracy(test) = 0.1532\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 7 2 1 3 1 4 3 1 3 6 1 7 2 8 1 1 4 0 1 1 2 0 7 3 3 1 7 8 6 1 8 1 6\n",
      " 0 7 6 1 8 1 1 7 7 8 1 7 3 3 0 7 1 7 8 0 7 4 1 4 1 6 0 6 1 6 1 0 0 1 7 1 6\n",
      " 3 0 3 1 1 7 0 0 0 6 7 8 7 9 0 4 6 7 4 6 8 0 1 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 7 4 0 7 0 6 9 0 1 3 4 7 6 4 7 6 4 8 4 0 7 4 0 1 3 1 3 6 3 0 7\n",
      " 1 2 1 1 7 4 1 1 3 1 6 4 4 6 3 8 7 6 0 4 1 4 1 7 0 7 8 3 1 6 4 3 0 7 0 0 8\n",
      " 1 7 3 7 1 3 7 6 2 7 8 4 7 7 6 1 3 6 1 3 1 4 1 7 6 4]\n",
      "1: weight=variable W([[[[ -2.51581013e-01  -2.16729417e-01  -1.62252322e-01\n",
      "                -1.35238945e-01  -4.92546201e-01]\n",
      "              [ -3.73490363e-01  -3.11963230e-01  -3.26328635e-01\n",
      "                -3.76423359e-01  -3.78201723e-01]\n",
      "              [ -3.00328046e-01  -1.76203772e-01  -4.98564154e-01\n",
      "                -5.91727436e-01  -3.11780155e-01]\n",
      "              [ -2.12475643e-01  -3.70322406e-01  -2.07499459e-01\n",
      "                -1.93304673e-01  -3.96296322e-01]\n",
      "              [ -4.80839759e-01  -2.20947459e-01  -4.77467924e-01\n",
      "                -4.65887427e-01   3.93100083e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -1.76290706e-01   3.27650726e-01   1.65233687e-01\n",
      "                 3.58881801e-01   2.88853943e-01]\n",
      "              [  2.20233172e-01  -1.04416907e-03   4.54935014e-01\n",
      "                 9.15416360e-01   6.59558296e-01]\n",
      "              [ -3.55303854e-01   1.31028235e-01   5.96808851e-01\n",
      "                 4.23933923e-01   8.62210214e-01]\n",
      "              [ -1.32870093e-01   6.07197173e-02   7.10731924e-01\n",
      "                 3.71711493e-01   8.30280304e-01]\n",
      "              [ -1.97795227e-01  -6.84340391e-03   2.38036245e-01\n",
      "                 7.35989869e-01   4.24807459e-01]]]\n",
      "\n",
      "\n",
      "            [[[  2.79329002e-01  -2.49913245e-01  -5.79356909e-01\n",
      "                -3.00955296e-01  -9.45033729e-01]\n",
      "              [ -1.01262257e-01  -3.90158683e-01  -4.67699707e-01\n",
      "                -2.79729754e-01  -8.72094095e-01]\n",
      "              [  1.36559144e-01  -3.77874732e-01  -6.57283247e-01\n",
      "                -3.12275380e-01  -4.74168807e-01]\n",
      "              [ -4.22295302e-01  -2.99818516e-01  -5.93995869e-01\n",
      "                -7.54686236e-01  -2.20491797e-01]\n",
      "              [ -1.75671369e-01  -2.19148710e-01  -5.94244421e-01\n",
      "                -5.33046067e-01  -4.74902600e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -5.33136725e-01  -7.56921589e-01  -1.36395410e-01\n",
      "                -2.48763397e-01   6.51808321e-01]\n",
      "              [ -4.02096361e-01  -5.96246898e-01  -4.29612517e-01\n",
      "                -1.99908651e-02   4.17572707e-01]\n",
      "              [ -4.03053403e-01  -6.95069671e-01  -4.96465042e-02\n",
      "                 9.93414000e-02   4.34807062e-01]\n",
      "              [ -4.09851909e-01  -3.97807479e-01  -6.50332332e-01\n",
      "                -2.66834557e-01   6.82576716e-01]\n",
      "              [ -6.06372297e-01  -7.35861957e-01  -4.26825315e-01\n",
      "                -4.13890816e-02   6.32296562e-01]]]\n",
      "\n",
      "\n",
      "            [[[  1.05408087e-01   3.04149657e-01   4.49395806e-01\n",
      "                 1.84666693e-01   2.36424543e-02]\n",
      "              [  3.85994673e-01   5.00642896e-01   4.67175663e-01\n",
      "                 3.86959970e-01   2.93048561e-01]\n",
      "              [  6.37256086e-01   4.09840524e-01   3.93534750e-01\n",
      "                 4.88909423e-01   5.62687457e-01]\n",
      "              [  2.59064168e-01   1.10456675e-01   5.85959733e-01\n",
      "                 4.68822032e-01   1.17393956e-01]\n",
      "              [  4.10359949e-01   5.30808985e-01   2.83374727e-01\n",
      "                 4.16393608e-01   1.44862175e-01]]]\n",
      "\n",
      "\n",
      "            [[[  4.01353329e-01   2.23814815e-01   3.24945301e-01\n",
      "                 4.85938281e-01   7.29714287e-04]\n",
      "              [  5.57526827e-01   3.40326399e-01   3.91725838e-01\n",
      "                 2.19528392e-01   1.68386072e-01]\n",
      "              [  6.15119338e-01   5.85948944e-01   6.58875942e-01\n",
      "                 2.82402217e-01   1.65794298e-01]\n",
      "              [  1.17547445e-01   8.47230315e-01   2.13025972e-01\n",
      "                 3.66664559e-01   3.20875347e-01]\n",
      "              [  2.89000630e-01   4.15406674e-01   1.41323477e-01\n",
      "                 4.04584646e-01   1.68822616e-01]]]]), bias=variable b([ 0.16929667 -0.46105006  0.29316133  0.08779844 -0.40198669\n",
      "            -0.40838382])\n",
      "Epoch 3 loss(train) = variable(146.65597534179688), accuracy(train) = 0.5995, accuracy(test) = 0.5965\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 1 3 6 1 7 2 8 6 7 4 0 9 1 2 3 9 3 3 9 3 8 6 7 8 5 6\n",
      " 0 9 6 1 8 7 7 3 9 8 5 3 3 3 0 7 4 9 8 0 9 9 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 3 1 1 9 0 0 2 6 7 8 7 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 9 4 5 9 0 6 9 0 1 3 9 7 2 4 9 6 4 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 6 3 3 3 6 9 4 6 3 8 7 6 0 4 1 9 5 7 8 9 2 9 9 4 4 8 0 7 0 2 3\n",
      " 1 9 3 7 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 5 9 1 9 6 9]\n",
      "1: weight=variable W([[[[-0.19822481 -0.21699791 -0.21643211 -0.22089596 -0.5670467 ]\n",
      "              [-0.36033043 -0.36155528 -0.42424598 -0.48531884 -0.436351  ]\n",
      "              [-0.3239601  -0.25939116 -0.60883957 -0.67084825 -0.29953861]\n",
      "              [-0.26223356 -0.47140357 -0.31706858 -0.24149752 -0.33838001]\n",
      "              [-0.52987927 -0.30783704 -0.54395449 -0.45484039  0.48115808]]]\n",
      "\n",
      "\n",
      "            [[[-0.25887677  0.25526038  0.09849569  0.30836618  0.291455  ]\n",
      "              [ 0.15982024 -0.03537768  0.44960567  0.99561954  0.76305056]\n",
      "              [-0.41250166  0.11481746  0.64729786  0.5577535   0.95955402]\n",
      "              [-0.19031116  0.04260637  0.75757945  0.46480623  0.82173705]\n",
      "              [-0.26879182 -0.05311868  0.2180329   0.69915175  0.32481447]]]\n",
      "\n",
      "\n",
      "            [[[ 0.36205804 -0.18635227 -0.57037508 -0.36128592 -1.02860105]\n",
      "              [-0.04207878 -0.37398961 -0.54434544 -0.40247777 -0.96223158]\n",
      "              [ 0.18188827 -0.39682254 -0.77401567 -0.44519576 -0.53203446]\n",
      "              [-0.38527143 -0.33269736 -0.69812715 -0.82800323 -0.19277737]\n",
      "              [-0.15713815 -0.27532429 -0.68792182 -0.55283839 -0.39478469]]]\n",
      "\n",
      "\n",
      "            [[[-0.54985172 -0.80574286 -0.19147794 -0.25979647  0.70863128]\n",
      "              [-0.49342406 -0.70859772 -0.52382284 -0.05647841  0.46987477]\n",
      "              [-0.53614306 -0.83243585 -0.14655079  0.07999963  0.5015474 ]\n",
      "              [-0.53905112 -0.49366966 -0.65809399 -0.2095643   0.76024747]\n",
      "              [-0.70112509 -0.76577997 -0.37874731  0.03861693  0.70981836]]]\n",
      "\n",
      "\n",
      "            [[[ 0.03148247  0.23237255  0.40545744  0.18459244  0.0167962 ]\n",
      "              [ 0.3647663   0.53912586  0.54652566  0.48039114  0.33843997]\n",
      "              [ 0.65394402  0.5058403   0.50617993  0.5761019   0.56896478]\n",
      "              [ 0.26728705  0.18531856  0.66267389  0.48524156  0.07065268]\n",
      "              [ 0.39425474  0.54841697  0.2762697   0.35447866  0.06792817]]]\n",
      "\n",
      "\n",
      "            [[[ 0.31065407  0.14391625  0.28256488  0.47198686 -0.0265738 ]\n",
      "              [ 0.53033233  0.38391942  0.48251677  0.30591241  0.19061796]\n",
      "              [ 0.63953048  0.69303972  0.77550298  0.35524952  0.15729038]\n",
      "              [ 0.13233738  0.92445123  0.27014372  0.36008355  0.26825306]\n",
      "              [ 0.26526469  0.40810233  0.0960136   0.31875461  0.08092733]]]]), bias=variable b([ 0.19835103 -0.52845174  0.32914838  0.08958696 -0.47505224\n",
      "            -0.48660788])\n",
      "Epoch 4 loss(train) = variable(86.44977569580078), accuracy(train) = 0.7763, accuracy(test) = 0.7611\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 7 4 0 9 1 2 2 4 3 3 9 3 8 6 7 8 5 6\n",
      " 0 7 6 1 8 7 7 3 9 8 5 3 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 3 1 1 9 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 4 5 9 0 6 9 0 1 3 9 7 2 4 9 6 4 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 4 2 9 9 6 4 8 0 7 0 2 8\n",
      " 1 9 3 3 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 8 4 1 9 6 9]\n",
      "1: weight=variable W([[[[-0.14101873 -0.18374741 -0.22273952 -0.25764778 -0.60017985]\n",
      "              [-0.3328433  -0.38054574 -0.48339114 -0.55476123 -0.45988363]\n",
      "              [-0.3213574  -0.30591756 -0.67701524 -0.7050789  -0.25661185]\n",
      "              [-0.27025211 -0.52375728 -0.37102434 -0.23253329 -0.26003721]\n",
      "              [-0.53411514 -0.34332711 -0.55442315 -0.40314549  0.56626511]]]\n",
      "\n",
      "\n",
      "            [[[-0.30909491  0.21014005  0.05228483  0.26657617  0.27614242]\n",
      "              [ 0.12470114 -0.05800819  0.42809203  1.02587473  0.81322056]\n",
      "              [-0.45172763  0.0998393   0.65520912  0.64046669  1.00179005]\n",
      "              [-0.23115769  0.0188539   0.75077826  0.5007202   0.78424555]\n",
      "              [-0.31303841 -0.08532728  0.19018927  0.66816956  0.25895476]]]\n",
      "\n",
      "\n",
      "            [[[ 0.4176273  -0.1269751  -0.53552163 -0.37315607 -1.06900966]\n",
      "              [ 0.00733176 -0.33950135 -0.57845706 -0.47616237 -1.00853431]\n",
      "              [ 0.23488669 -0.37816188 -0.84162343 -0.52525169 -0.53217685]\n",
      "              [-0.32942557 -0.32136548 -0.75665122 -0.85145932 -0.12826023]\n",
      "              [-0.11406542 -0.28691468 -0.73628259 -0.53557611 -0.30792391]]]\n",
      "\n",
      "\n",
      "            [[[-0.53228033 -0.81649733 -0.21099018 -0.25018725  0.75901461]\n",
      "              [-0.53858441 -0.77434826 -0.57467705 -0.06637805  0.51576328]\n",
      "              [-0.61819649 -0.91555673 -0.1918616   0.08769526  0.55683386]\n",
      "              [-0.61777055 -0.53754538 -0.63202393 -0.15452088  0.81917191]\n",
      "              [-0.73935866 -0.75389242 -0.32310852  0.10430075  0.77147967]]]\n",
      "\n",
      "\n",
      "            [[[-0.00509809  0.1858281   0.36392337  0.17345265  0.0170659 ]\n",
      "              [ 0.3511942   0.54347998  0.57424134  0.52862448  0.36590034]\n",
      "              [ 0.64770508  0.55263513  0.5726468   0.61290282  0.56252497]\n",
      "              [ 0.23331343  0.20129442  0.6851474   0.4637616   0.03995236]\n",
      "              [ 0.35732341  0.53587699  0.24954793  0.30471841  0.02650613]]]\n",
      "\n",
      "\n",
      "            [[[ 0.25860897  0.08773352  0.23834258  0.44901344 -0.04299922]\n",
      "              [ 0.5079686   0.38635474  0.51725847  0.34523413  0.20209241]\n",
      "              [ 0.63808399  0.75121778  0.84068871  0.37275797  0.14211838]\n",
      "              [ 0.10339352  0.94125587  0.26492503  0.32212448  0.23385422]\n",
      "              [ 0.23029259  0.38435563  0.0487917   0.26066649  0.03339801]]]]), bias=variable b([ 0.21279092 -0.5571925   0.34499237  0.08159962 -0.50623548\n",
      "            -0.52147132])\n",
      "Epoch 5 loss(train) = variable(66.73696899414062), accuracy(train) = 0.8194, accuracy(test) = 0.8036\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 3 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 9 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 4 5 9 0 6 9 0 1 3 9 7 8 4 9 6 4 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 9 4 6 3 5 5 6 0 4 1 9 5 7 8 4 2 7 9 6 4 8 0 7 0 2 8\n",
      " 1 9 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 8 4 1 9 6 9]\n",
      "1: weight=variable W([[[[ -9.92954373e-02  -1.49063453e-01  -2.08085820e-01\n",
      "                -2.65689045e-01  -6.09013379e-01]\n",
      "              [ -3.18272591e-01  -3.98530811e-01  -5.29233634e-01\n",
      "                -6.08379602e-01  -4.71111685e-01]\n",
      "              [ -3.18493247e-01  -3.43295425e-01  -7.30330110e-01\n",
      "                -7.26340950e-01  -2.16138050e-01]\n",
      "              [ -2.64716327e-01  -5.56688428e-01  -4.02819067e-01\n",
      "                -2.13243991e-01  -1.95116892e-01]\n",
      "              [ -5.17254531e-01  -3.53095323e-01  -5.46193421e-01\n",
      "                -3.55514497e-01   6.31762385e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -3.48016173e-01   1.75676823e-01   1.45634310e-02\n",
      "                 2.28915632e-01   2.54126519e-01]\n",
      "              [  1.03498705e-01  -6.52438924e-02   4.16672140e-01\n",
      "                 1.04350400e+00   8.43525410e-01]\n",
      "              [ -4.75279510e-01   9.98134539e-02   6.61146522e-01\n",
      "                 7.06202209e-01   1.03109848e+00]\n",
      "              [ -2.58033216e-01   4.63912816e-04   7.29069412e-01\n",
      "                 5.14290035e-01   7.55188525e-01]\n",
      "              [ -3.45405251e-01  -1.13361873e-01   1.56636789e-01\n",
      "                 6.38184547e-01   2.11759448e-01]]]\n",
      "\n",
      "\n",
      "            [[[  4.51316088e-01  -8.58482867e-02  -5.01791596e-01\n",
      "                -3.64838421e-01  -1.08267093e+00]\n",
      "              [  3.49215977e-02  -3.14446598e-01  -5.99227846e-01\n",
      "                -5.29583871e-01  -1.03697217e+00]\n",
      "              [  2.73578942e-01  -3.56994152e-01  -8.88941586e-01\n",
      "                -5.88759005e-01  -5.22931159e-01]\n",
      "              [ -2.79180378e-01  -2.99233198e-01  -7.98803627e-01\n",
      "                -8.68948460e-01  -7.63714463e-02]\n",
      "              [ -6.73312098e-02  -2.79177934e-01  -7.66686261e-01\n",
      "                -5.22072017e-01  -2.43160635e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -5.10762691e-01  -8.14172745e-01  -2.16743842e-01\n",
      "                -2.39280447e-01   7.95174181e-01]\n",
      "              [ -5.68439066e-01  -8.20767581e-01  -6.09653234e-01\n",
      "                -7.46918023e-02   5.46413302e-01]\n",
      "              [ -6.79564893e-01  -9.76570547e-01  -2.20130742e-01\n",
      "                 9.43747237e-02   5.94900787e-01]\n",
      "              [ -6.73349679e-01  -5.65139174e-01  -6.09885812e-01\n",
      "                -1.15472898e-01   8.58986378e-01]\n",
      "              [ -7.51448393e-01  -7.37242818e-01  -2.80186832e-01\n",
      "                 1.52763247e-01   8.16213727e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -2.55725253e-02   1.50349528e-01   3.23609293e-01\n",
      "                 1.51685357e-01   1.36645529e-02]\n",
      "              [  3.54348093e-01   5.45420110e-01   5.84056973e-01\n",
      "                 5.59638262e-01   3.91176283e-01]\n",
      "              [  6.48247302e-01   5.85471690e-01   6.27551019e-01\n",
      "                 6.42317712e-01   5.67338765e-01]\n",
      "              [  1.90978706e-01   1.90205723e-01   6.91044986e-01\n",
      "                 4.47787046e-01   2.91243047e-02]\n",
      "              [  3.09081316e-01   5.01758814e-01   2.17404470e-01\n",
      "                 2.66323417e-01  -3.26244812e-03]]]\n",
      "\n",
      "\n",
      "            [[[  2.22333133e-01   4.10861522e-02   1.93773448e-01\n",
      "                 4.16173041e-01  -5.96272983e-02]\n",
      "              [  5.02202928e-01   3.83350074e-01   5.34235597e-01\n",
      "                 3.70859593e-01   2.16630772e-01]\n",
      "              [  6.42789483e-01   7.95160055e-01   8.92756164e-01\n",
      "                 3.86411786e-01   1.42559767e-01]\n",
      "              [  6.30933344e-02   9.30050910e-01   2.46910125e-01\n",
      "                 2.94643641e-01   2.19642386e-01]\n",
      "              [  1.84941709e-01   3.46154362e-01   5.58501761e-03\n",
      "                 2.17239797e-01  -9.89691354e-04]]]]), bias=variable b([ 0.22357272 -0.5757817   0.35507786  0.06967917 -0.52711469\n",
      "            -0.54607868])\n",
      "Epoch 6 loss(train) = variable(55.650875091552734), accuracy(train) = 0.8494, accuracy(test) = 0.8368\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 3 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 9 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 4 5 9 0 6 9 0 1 5 9 7 8 4 9 6 4 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 9 4 6 8 5 5 6 0 4 1 9 5 7 8 4 2 7 9 6 4 8 0 7 0 2 8\n",
      " 1 9 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 8 4 1 8 6 9]\n",
      "1: weight=variable W([[[[ -6.73337132e-02  -1.15011677e-01  -1.81618109e-01\n",
      "                -2.57268310e-01  -6.05648994e-01]\n",
      "              [ -3.14655304e-01  -4.17914212e-01  -5.67937672e-01\n",
      "                -6.54950678e-01  -4.78307694e-01]\n",
      "              [ -3.19388539e-01  -3.79396468e-01  -7.75282800e-01\n",
      "                -7.43347824e-01  -1.82597965e-01]\n",
      "              [ -2.54462957e-01  -5.80490530e-01  -4.22194630e-01\n",
      "                -1.93197012e-01  -1.42075196e-01]\n",
      "              [ -4.91624832e-01  -3.51127297e-01  -5.31292379e-01\n",
      "                -3.14081788e-01   6.84856296e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -3.81245732e-01   1.45647064e-01  -1.93981268e-02\n",
      "                 1.94746777e-01   2.31335461e-01]\n",
      "              [  9.03159082e-02  -6.40313551e-02   4.11431432e-01\n",
      "                 1.05592835e+00   8.63290012e-01]\n",
      "              [ -4.88819510e-01   1.09122954e-01   6.71292663e-01\n",
      "                 7.63623238e-01   1.05714214e+00]\n",
      "              [ -2.76967198e-01  -1.15915751e-02   7.05404162e-01\n",
      "                 5.19511938e-01   7.35692739e-01]\n",
      "              [ -3.70971441e-01  -1.36379063e-01   1.25317141e-01\n",
      "                 6.10878706e-01   1.74934745e-01]]]\n",
      "\n",
      "\n",
      "            [[[  4.73065645e-01  -5.71538769e-02  -4.72152412e-01\n",
      "                -3.48512352e-01  -1.08331752e+00]\n",
      "              [  4.83550280e-02  -2.98236728e-01  -6.15441918e-01\n",
      "                -5.73693752e-01  -1.05800915e+00]\n",
      "              [  3.00908208e-01  -3.37394506e-01  -9.22253609e-01\n",
      "                -6.42592013e-01  -5.12441099e-01]\n",
      "              [ -2.36036420e-01  -2.76672572e-01  -8.33813250e-01\n",
      "                -8.87092948e-01  -3.55805904e-02]\n",
      "              [ -2.29968764e-02  -2.66828507e-01  -7.91538179e-01\n",
      "                -5.16008973e-01  -1.93330064e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -4.87235278e-01  -8.06127250e-01  -2.17905611e-01\n",
      "                -2.30547011e-01   8.21338475e-01]\n",
      "              [ -5.91934502e-01  -8.59868884e-01  -6.40104830e-01\n",
      "                -8.48853961e-02   5.66456974e-01]\n",
      "              [ -7.31407106e-01  -1.02748895e+00  -2.43809953e-01\n",
      "                 9.59556848e-02   6.20716691e-01]\n",
      "              [ -7.14353621e-01  -5.83777726e-01  -5.93232274e-01\n",
      "                -8.81262273e-02   8.85828197e-01]\n",
      "              [ -7.51989067e-01  -7.20437229e-01  -2.45535657e-01\n",
      "                 1.89334616e-01   8.47615302e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -3.87566611e-02   1.20610923e-01   2.85250574e-01\n",
      "                 1.23979867e-01   5.75017650e-03]\n",
      "              [  3.68277401e-01   5.48171580e-01   5.84737718e-01\n",
      "                 5.79393327e-01   4.13458675e-01]\n",
      "              [  6.57442808e-01   6.13077164e-01   6.75970614e-01\n",
      "                 6.69259548e-01   5.79440773e-01]\n",
      "              [  1.50106430e-01   1.68337986e-01   6.90609157e-01\n",
      "                 4.38664764e-01   3.02940719e-02]\n",
      "              [  2.60843843e-01   4.61394101e-01   1.85763761e-01\n",
      "                 2.34862462e-01  -2.70383582e-02]]]\n",
      "\n",
      "\n",
      "            [[[  1.93790123e-01   1.43202778e-04   1.50487974e-01\n",
      "                 3.79050970e-01  -7.83572420e-02]\n",
      "              [  5.07508636e-01   3.78427535e-01   5.40023625e-01\n",
      "                 3.87789220e-01   2.32056424e-01]\n",
      "              [  6.53961718e-01   8.31193686e-01   9.37907219e-01\n",
      "                 4.01350528e-01   1.52582958e-01]\n",
      "              [  2.28130966e-02   9.06908333e-01   2.27923900e-01\n",
      "                 2.77525306e-01   2.17414424e-01]\n",
      "              [  1.39345929e-01   3.04853857e-01  -3.38330083e-02\n",
      "                 1.81284040e-01  -3.07044107e-02]]]]), bias=variable b([ 0.23267458 -0.58899748  0.36206517  0.05568178 -0.54308134\n",
      "            -0.56565565])\n",
      "Epoch 7 loss(train) = variable(48.24488830566406), accuracy(train) = 0.864, accuracy(test) = 0.854\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 3 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 9 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 4 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 9 4 6 8 5 5 6 0 4 1 9 5 7 8 4 2 7 9 6 4 8 0 7 0 2 8\n",
      " 1 9 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 8 4 1 8 6 9]\n",
      "1: weight=variable W([[[[-0.03890558 -0.0794196  -0.14566366 -0.23850708 -0.59674227]\n",
      "              [-0.31503832 -0.43594062 -0.59887129 -0.69561797 -0.4844951 ]\n",
      "              [-0.32169062 -0.41422373 -0.81513649 -0.75833261 -0.15424825]\n",
      "              [-0.24266817 -0.59920269 -0.43425214 -0.17200656 -0.09573093]\n",
      "              [-0.46315804 -0.34293705 -0.51198769 -0.2742286   0.73199081]]]\n",
      "\n",
      "\n",
      "            [[[-0.41349137  0.11567857 -0.05215127  0.1630659   0.21048225]\n",
      "              [ 0.07710347 -0.06108944  0.40777463  1.06230068  0.8750605 ]\n",
      "              [-0.49743554  0.12239544  0.68289208  0.81328636  1.08021367]\n",
      "              [-0.29037493 -0.01918188  0.68458652  0.52343136  0.72287905]\n",
      "              [-0.39269698 -0.15573987  0.09723134  0.58667964  0.1436542 ]]]\n",
      "\n",
      "\n",
      "            [[[ 0.49097821 -0.0323751  -0.44463205 -0.32972515 -1.07814884]\n",
      "              [ 0.05797862 -0.28459626 -0.62751704 -0.61208266 -1.07442904]\n",
      "              [ 0.32473195 -0.31721869 -0.94681621 -0.69272363 -0.50254565]\n",
      "              [-0.19608821 -0.25288635 -0.86458582 -0.90479565 -0.00125838]\n",
      "              [ 0.01877075 -0.25197476 -0.81413579 -0.51287818 -0.1511942 ]]]\n",
      "\n",
      "\n",
      "            [[[-0.46397358 -0.79589587 -0.21747388 -0.22283724  0.84273267]\n",
      "              [-0.61074585 -0.8940475  -0.66693234 -0.09476461  0.58159906]\n",
      "              [-0.77406794 -1.07003117 -0.26386261  0.09492409  0.64008188]\n",
      "              [-0.74542791 -0.59501058 -0.57792282 -0.06623966  0.90570223]\n",
      "              [-0.74787778 -0.70254141 -0.21489805  0.21938494  0.87200141]]]\n",
      "\n",
      "\n",
      "            [[[-0.04906321  0.09420276  0.25046992  0.09658911 -0.00327678]\n",
      "              [ 0.38483107  0.54833621  0.57844472  0.59160346  0.43370759]\n",
      "              [ 0.6698221   0.63561451  0.71840835  0.69343781  0.59374487]\n",
      "              [ 0.1136117   0.14340812  0.68932927  0.4341132   0.03674747]\n",
      "              [ 0.21645169  0.42256305  0.15671836  0.20826998 -0.04813785]]]\n",
      "\n",
      "\n",
      "            [[[ 0.16853559 -0.03700162  0.11081053  0.3437562  -0.09662624]\n",
      "              [ 0.5158636   0.37088677  0.53857052  0.399304    0.24608634]\n",
      "              [ 0.66773289  0.85925466  0.97642601  0.41460836  0.1649797 ]\n",
      "              [-0.01321706  0.88015246  0.2096141   0.26566276  0.21932697]\n",
      "              [ 0.09815924  0.26633644 -0.0698122   0.14867061 -0.06031477]]]]), bias=variable b([ 0.24128854 -0.59851992  0.36744794  0.04119128 -0.55551642\n",
      "            -0.58165765])\n",
      "Epoch 8 loss(train) = variable(42.969051361083984), accuracy(train) = 0.874, accuracy(test) = 0.8679\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 3 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 9 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 4 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 8 5 5 6 0 4 1 9 5 7 8 9 2 7 9 6 4 8 0 7 0 2 8\n",
      " 1 9 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 8 4 1 8 6 9]\n",
      "1: weight=variable W([[[[-0.01087496 -0.04167219 -0.10306015 -0.21323645 -0.58407968]\n",
      "              [-0.31829897 -0.45136765 -0.6236552  -0.73238677 -0.48950604]\n",
      "              [-0.32672691 -0.44787711 -0.85191393 -0.77225852 -0.12862991]\n",
      "              [-0.23114511 -0.61253935 -0.43801719 -0.14901504 -0.05238747]\n",
      "              [-0.43322161 -0.32913005 -0.48662731 -0.23302595  0.7765407 ]]]\n",
      "\n",
      "\n",
      "            [[[-0.44475353  0.08620625 -0.0838882   0.13265696  0.19076301]\n",
      "              [ 0.06271381 -0.06002741  0.40258476  1.0626384   0.88131577]\n",
      "              [-0.50473678  0.13654566  0.6941551   0.85496742  1.09937286]\n",
      "              [-0.30177861 -0.02377639  0.66730821  0.52587968  0.71319598]\n",
      "              [-0.41197866 -0.17162606  0.07324642  0.56584734  0.11604733]]]\n",
      "\n",
      "\n",
      "            [[[ 0.5091207  -0.00833388 -0.41693726 -0.30888477 -1.06981969]\n",
      "              [ 0.06653778 -0.27095839 -0.6351189  -0.64496684 -1.08644283]\n",
      "              [ 0.3459639  -0.29721567 -0.96508676 -0.73883694 -0.49206886]\n",
      "              [-0.15943408 -0.22947347 -0.8919971  -0.92132455  0.02940888]\n",
      "              [ 0.05908816 -0.23711313 -0.83489543 -0.51119137 -0.11382011]]]\n",
      "\n",
      "\n",
      "            [[[-0.43993354 -0.78356528 -0.21544679 -0.21500647  0.86174393]\n",
      "              [-0.62456626 -0.92339861 -0.69110054 -0.10456952  0.59407651]\n",
      "              [-0.80864376 -1.10524511 -0.28105977  0.09266825  0.65585935]\n",
      "              [-0.76881349 -0.60155964 -0.56414491 -0.04765909  0.9216063 ]\n",
      "              [-0.74193484 -0.68480092 -0.18719073  0.24549018  0.89202535]]]\n",
      "\n",
      "\n",
      "            [[[-0.059352    0.06980327  0.21900247  0.07063099 -0.01253471]\n",
      "              [ 0.39990062  0.5457533   0.56711012  0.59825742  0.45110652]\n",
      "              [ 0.68345368  0.65373904  0.75468165  0.71376276  0.6072557 ]\n",
      "              [ 0.08286268  0.11933759  0.68709809  0.43068668  0.04450487]\n",
      "              [ 0.17954423  0.38958308  0.13139172  0.18463244 -0.06817136]]]\n",
      "\n",
      "\n",
      "            [[[ 0.14541389 -0.07002715  0.07562261  0.31145492 -0.11424993]\n",
      "              [ 0.52389199  0.35955074  0.53162932  0.40673506  0.25765985]\n",
      "              [ 0.68226177  0.88090175  1.00860512  0.42534149  0.17556663]\n",
      "              [-0.04380764  0.85366076  0.1916685   0.25530618  0.2210217 ]\n",
      "              [ 0.06299598  0.23241879 -0.10360732  0.11790984 -0.09000896]]]]), bias=variable b([ 0.25015596 -0.60547137  0.37208065  0.02675092 -0.56533551\n",
      "            -0.5952329 ])\n",
      "Epoch 9 loss(train) = variable(38.56932067871094), accuracy(train) = 0.8859, accuracy(test) = 0.8787\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 3 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 9 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 4 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 8 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 8 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 8 4 1 8 6 9]\n",
      "1: weight=variable W([[[[ 0.01794009 -0.00120175 -0.05447543 -0.18206106 -0.56808817]\n",
      "              [-0.32254958 -0.46545014 -0.64375079 -0.76737642 -0.49465069]\n",
      "              [-0.3334077  -0.48116279 -0.88584942 -0.7866326  -0.10614816]\n",
      "              [-0.2210805  -0.62216353 -0.434425   -0.12381038 -0.01198789]\n",
      "              [-0.40228519 -0.30982712 -0.45613331 -0.19078642  0.81898504]]]\n",
      "\n",
      "\n",
      "            [[[-0.47461614  0.05900435 -0.11361358  0.10433791  0.17250746]\n",
      "              [ 0.04883176 -0.06014292  0.39630961  1.05864358  0.88386631]\n",
      "              [-0.51121348  0.1507784   0.70531726  0.89011741  1.11546373]\n",
      "              [-0.3115474  -0.02585897  0.6540029   0.52762234  0.70497531]\n",
      "              [-0.42830414 -0.18448505  0.05307753  0.54751009  0.09045284]]]\n",
      "\n",
      "\n",
      "            [[[ 0.5287984   0.0159456  -0.38998732 -0.28795633 -1.05974686]\n",
      "              [ 0.07647365 -0.25724772 -0.63982594 -0.67479092 -1.09503019]\n",
      "              [ 0.36593381 -0.27749816 -0.97861731 -0.78214949 -0.4818629 ]\n",
      "              [-0.12512307 -0.2066431  -0.9159829  -0.93719405  0.05651523]\n",
      "              [ 0.09623027 -0.22191536 -0.85362244 -0.50986856 -0.07973798]]]\n",
      "\n",
      "\n",
      "            [[[-0.41584298 -0.77052373 -0.21264648 -0.20749761  0.87802082]\n",
      "              [-0.63532698 -0.94931477 -0.71253419 -0.11323641  0.60482472]\n",
      "              [-0.83911693 -1.13541925 -0.29640287  0.08973739  0.66888255]\n",
      "              [-0.78662723 -0.605398   -0.55136567 -0.03210324  0.93361574]\n",
      "              [-0.73526257 -0.66838884 -0.16286531  0.26727471  0.90770674]]]\n",
      "\n",
      "\n",
      "            [[[-0.07032125  0.04612974  0.18983945  0.04635065 -0.02195333]\n",
      "              [ 0.41297862  0.54109907  0.55242503  0.60129029  0.46691546]\n",
      "              [ 0.69757563  0.66877514  0.78555077  0.7305274   0.62024885]\n",
      "              [ 0.05701664  0.09736814  0.68507487  0.4283765   0.05259757]\n",
      "              [ 0.14815131  0.36138836  0.10939541  0.16361454 -0.08779504]]]\n",
      "\n",
      "\n",
      "            [[[ 0.12391932 -0.10006991  0.04415848  0.28162521 -0.13129792]\n",
      "              [ 0.53005022  0.34616625  0.52268791  0.4115752   0.2665996 ]\n",
      "              [ 0.69657004  0.89767355  1.03532696  0.43413079  0.1848221 ]\n",
      "              [-0.07028542  0.82829267  0.17419931  0.2463553   0.22222343]\n",
      "              [ 0.03243408  0.20124114 -0.13634719  0.08531294 -0.1223864 ]]]]), bias=variable b([ 0.25946078 -0.61045963  0.37627023  0.01255377 -0.57314408\n",
      "            -0.60700035])\n",
      "Epoch 10 loss(train) = variable(34.71783447265625), accuracy(train) = 0.8965, accuracy(test) = 0.8911\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 3 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 8 4 1 8 6 9]\n",
      "1: weight=variable W([[[[  4.61219549e-02   4.19840366e-02  -1.09821686e-03\n",
      "                -1.46050736e-01  -5.49862921e-01]\n",
      "              [ -3.27970743e-01  -4.78453279e-01  -6.59726799e-01\n",
      "                -7.99562812e-01  -5.01314819e-01]\n",
      "              [ -3.41959625e-01  -5.14448404e-01  -9.17744815e-01\n",
      "                -8.03255320e-01  -8.78572315e-02]\n",
      "              [ -2.12635249e-01  -6.28950417e-01  -4.24918085e-01\n",
      "                -9.76388082e-02   2.50225328e-02]\n",
      "              [ -3.70976835e-01  -2.85414547e-01  -4.20655608e-01\n",
      "                -1.48262531e-01   8.59073758e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -5.03064752e-01   3.28868926e-02  -1.41260102e-01\n",
      "                 7.75266886e-02   1.55163541e-01]\n",
      "              [  3.42833363e-02  -6.11568540e-02   3.89531702e-01\n",
      "                 1.05212843e+00   8.83539140e-01]\n",
      "              [ -5.16101003e-01   1.65787473e-01   7.17022419e-01\n",
      "                 9.20753479e-01   1.12952435e+00]\n",
      "              [ -3.19051594e-01  -2.49906927e-02   6.44158721e-01\n",
      "                 5.29107869e-01   6.97787464e-01]\n",
      "              [ -4.42025006e-01  -1.94284067e-01   3.72428447e-02\n",
      "                 5.31874835e-01   6.68915287e-02]]]\n",
      "\n",
      "\n",
      "            [[[  5.49408615e-01   4.11113650e-02  -3.63296598e-01\n",
      "                -2.66678482e-01  -1.04815280e+00]\n",
      "              [  8.74230489e-02  -2.43016198e-01  -6.41388059e-01\n",
      "                -7.01054871e-01  -1.10108745e+00]\n",
      "              [  3.83545101e-01  -2.58541465e-01  -9.88740146e-01\n",
      "                -8.21924984e-01  -4.71869737e-01]\n",
      "              [ -9.42994207e-02  -1.86486930e-01  -9.38591957e-01\n",
      "                -9.53087866e-01   8.08554217e-02]\n",
      "              [  1.29533142e-01  -2.08997995e-01  -8.70722651e-01\n",
      "                -5.09400427e-01  -4.86892089e-02]]]\n",
      "\n",
      "\n",
      "            [[[ -3.92326862e-01  -7.57255971e-01  -2.09020972e-01\n",
      "                -2.00120032e-01   8.92382920e-01]\n",
      "              [ -6.42815173e-01  -9.70333040e-01  -7.31363356e-01\n",
      "                -1.21170476e-01   6.13573015e-01]\n",
      "              [ -8.67212176e-01  -1.16304100e+00  -3.11068147e-01\n",
      "                 8.53595957e-02   6.78964555e-01]\n",
      "              [ -8.01661849e-01  -6.08138204e-01  -5.40708840e-01\n",
      "                -1.97791774e-02   9.42199886e-01]\n",
      "              [ -7.28772998e-01  -6.53990149e-01  -1.41955644e-01\n",
      "                 2.85046875e-01   9.19358730e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -8.12280551e-02   2.43883040e-02   1.63861349e-01\n",
      "                 2.43790671e-02  -3.10869291e-02]\n",
      "              [  4.24371123e-01   5.35210669e-01   5.36951065e-01\n",
      "                 6.02153420e-01   4.80853736e-01]\n",
      "              [  7.12262511e-01   6.81602538e-01   8.12538743e-01\n",
      "                 7.44892061e-01   6.32321119e-01]\n",
      "              [  3.48958895e-02   7.79993609e-02   6.83432877e-01\n",
      "                 4.26265895e-01   6.00995757e-02]\n",
      "              [  1.21423461e-01   3.37560087e-01   9.02075469e-02\n",
      "                 1.44171357e-01  -1.07136436e-01]]]\n",
      "\n",
      "\n",
      "            [[[  1.03763185e-01  -1.26457080e-01   1.67520009e-02\n",
      "                 2.54080266e-01  -1.47945464e-01]\n",
      "              [  5.36203265e-01   3.32935214e-01   5.13289273e-01\n",
      "                 4.14081186e-01   2.72747248e-01]\n",
      "              [  7.10626066e-01   9.10888314e-01   1.05806541e+00\n",
      "                 4.41459119e-01   1.92700997e-01]\n",
      "              [ -9.39670652e-02   8.04184139e-01   1.57624185e-01\n",
      "                 2.38563076e-01   2.22381458e-01]\n",
      "              [  5.26397070e-03   1.71545550e-01  -1.67854473e-01\n",
      "                 5.32735623e-02  -1.55173957e-01]]]]), bias=variable b([ 0.26921606 -0.61389542  0.38008666 -0.00131904 -0.57945287\n",
      "            -0.61732763])\n",
      "Epoch 11 loss(train) = variable(31.36573600769043), accuracy(train) = 0.9067, accuracy(test) = 0.9004\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 2 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 8 4 1 3 6 9]\n",
      "1: weight=variable W([[[[ 0.07330482  0.08609207  0.05496541 -0.10674381 -0.52984315]\n",
      "              [-0.33413392 -0.49019572 -0.67121774 -0.82959229 -0.50969833]\n",
      "              [-0.35289204 -0.54997414 -0.94976079 -0.82186085 -0.07259583]\n",
      "              [-0.20593739 -0.634278   -0.41095835 -0.07090321  0.05901262]\n",
      "              [-0.33929259 -0.25708413 -0.3825638  -0.10627755  0.89650261]]]\n",
      "\n",
      "\n",
      "            [[[-0.52912134  0.00902978 -0.16567114  0.05355051  0.14006424]\n",
      "              [ 0.02066074 -0.06164114  0.38361692  1.04428411  0.88298482]\n",
      "              [-0.51881057  0.18179417  0.72899687  0.94664431  1.14219666]\n",
      "              [-0.3246502  -0.02219343  0.637353    0.530595    0.69131583]\n",
      "              [-0.45422021 -0.20213777  0.02361535  0.51739663  0.04458962]]]\n",
      "\n",
      "\n",
      "            [[[ 0.57090652  0.06739148 -0.33660778 -0.24518062 -1.03557348]\n",
      "              [ 0.09964439 -0.22733317 -0.64101386 -0.72431451 -1.10441506]\n",
      "              [ 0.40047145 -0.23982462 -0.99662948 -0.86002463 -0.46224263]\n",
      "              [-0.06546322 -0.16739699 -0.96056187 -0.96910769  0.10291871]\n",
      "              [ 0.16035551 -0.19505455 -0.8858698  -0.50937641 -0.01979923]]]\n",
      "\n",
      "\n",
      "            [[[-0.37012294 -0.74446869 -0.20503061 -0.19278939  0.90539587]\n",
      "              [-0.64670366 -0.98733819 -0.74782234 -0.12787296  0.62127316]\n",
      "              [-0.89119428 -1.18702304 -0.32465288  0.08023548  0.68694729]\n",
      "              [-0.81378561 -0.60990685 -0.53173995 -0.0102322   0.94808084]\n",
      "              [-0.72306836 -0.6416766  -0.12385272  0.30000407  0.92844099]]]\n",
      "\n",
      "\n",
      "            [[[-0.09207665  0.00434937  0.14081526  0.00417623 -0.0391556 ]\n",
      "              [ 0.43528739  0.53005522  0.52240694  0.60222185  0.49403894]\n",
      "              [ 0.72746044  0.69296229  0.83669573  0.75764865  0.64413339]\n",
      "              [ 0.01590758  0.06046443  0.68183041  0.42379716  0.06728769]\n",
      "              [ 0.09790549  0.31639642  0.07257032  0.12566729 -0.12607196]]]\n",
      "\n",
      "\n",
      "            [[[ 0.08582593 -0.14906938 -0.0054078   0.22992776 -0.16375872]\n",
      "              [ 0.54187107  0.32121423  0.50674498  0.41687822  0.27777219]\n",
      "              [ 0.72437578  0.92062432  1.0777185   0.44797894  0.20006438]\n",
      "              [-0.11383535  0.78163868  0.14150994  0.23102261  0.22158988]\n",
      "              [-0.01977019  0.14118202 -0.1995118   0.02140559 -0.18727408]]]]), bias=variable b([ 0.279192   -0.61604714  0.38345608 -0.01461318 -0.58467096\n",
      "            -0.62645406])\n",
      "Epoch 12 loss(train) = variable(28.503341674804688), accuracy(train) = 0.9176, accuracy(test) = 0.9089\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 2 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 6 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 8 4 1 3 6 9]\n",
      "1: weight=variable W([[[[  9.74762514e-02   1.28302485e-01   1.11784332e-01\n",
      "                -6.48535192e-02  -5.07729590e-01]\n",
      "              [ -3.41946512e-01  -5.00449002e-01  -6.78666890e-01\n",
      "                -8.59064043e-01  -5.19181728e-01]\n",
      "              [ -3.66507828e-01  -5.85905194e-01  -9.81939673e-01\n",
      "                -8.44547808e-01  -6.13935068e-02]\n",
      "              [ -2.01746076e-01  -6.38388872e-01  -3.94210368e-01\n",
      "                -4.59237210e-02   8.94447118e-02]\n",
      "              [ -3.09145302e-01  -2.27004111e-01  -3.43098998e-01\n",
      "                -6.60513267e-02   9.30941343e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -5.52825809e-01  -1.31646441e-02  -1.88250110e-01\n",
      "                 3.08221318e-02   1.25525773e-01]\n",
      "              [  7.91674480e-03  -6.22668043e-02   3.77604991e-01\n",
      "                 1.03474164e+00   8.81379128e-01]\n",
      "              [ -5.19705653e-01   1.97683036e-01   7.40714312e-01\n",
      "                 9.69390273e-01   1.15412951e+00]\n",
      "              [ -3.28516811e-01  -1.79764014e-02   6.33137643e-01\n",
      "                 5.32924771e-01   6.87067211e-01]\n",
      "              [ -4.65200126e-01  -2.08582297e-01   1.21217035e-02\n",
      "                 5.04375219e-01   2.37834584e-02]]]\n",
      "\n",
      "\n",
      "            [[[  5.92156589e-01   9.33104828e-02  -3.10764581e-01\n",
      "                -2.25062266e-01  -1.02262557e+00]\n",
      "              [  1.12082228e-01  -2.12561697e-01  -6.39134645e-01\n",
      "                -7.45471358e-01  -1.10521924e+00]\n",
      "              [  4.15668935e-01  -2.23237127e-01  -1.00337875e+00\n",
      "                -8.96762967e-01  -4.53008741e-01]\n",
      "              [ -4.04489115e-02  -1.50584012e-01  -9.80260134e-01\n",
      "                -9.85216141e-01   1.22526303e-01]\n",
      "              [  1.86907783e-01  -1.82786793e-01  -8.99587810e-01\n",
      "                -5.09811401e-01   5.88944461e-03]]]\n",
      "\n",
      "\n",
      "            [[[ -3.48813385e-01  -7.31616020e-01  -2.01150164e-01\n",
      "                -1.85923517e-01   9.16917205e-01]\n",
      "              [ -6.47915542e-01  -1.00116205e+00  -7.62544811e-01\n",
      "                -1.34025916e-01   6.27701938e-01]\n",
      "              [ -9.12315488e-01  -1.20883143e+00  -3.38041604e-01\n",
      "                 7.39088580e-02   6.92686200e-01]\n",
      "              [ -8.24408114e-01  -6.11965358e-01  -5.24956822e-01\n",
      "                -3.52704269e-03   9.51114237e-01]\n",
      "              [ -7.18691111e-01  -6.31792128e-01  -1.08786322e-01\n",
      "                 3.11765939e-01   9.34910655e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -1.01265281e-01  -1.18607543e-02   1.21399671e-01\n",
      "                -1.42222149e-02  -4.58225459e-02]\n",
      "              [  4.44945782e-01   5.25277317e-01   5.08784950e-01\n",
      "                 6.00982845e-01   5.06829441e-01]\n",
      "              [  7.41944671e-01   7.03500390e-01   8.58984888e-01\n",
      "                 7.68182755e-01   6.56064332e-01]\n",
      "              [ -5.42479043e-04   4.43368107e-02   6.80775225e-01\n",
      "                 4.21777219e-01   7.52667636e-02]\n",
      "              [  7.76206702e-02   2.98020273e-01   5.70695177e-02\n",
      "                 1.09139465e-01  -1.43492416e-01]]]\n",
      "\n",
      "\n",
      "            [[[  6.89832792e-02  -1.68913633e-01  -2.37413999e-02\n",
      "                 2.09246606e-01  -1.77615896e-01]\n",
      "              [  5.46552002e-01   3.11195642e-01   5.02837718e-01\n",
      "                 4.20334280e-01   2.82503098e-01]\n",
      "              [  7.37669289e-01   9.28024948e-01   1.09559059e+00\n",
      "                 4.54661638e-01   2.07247168e-01]\n",
      "              [ -1.30833268e-01   7.61077702e-01   1.26665339e-01\n",
      "                 2.23927274e-01   2.21351817e-01]\n",
      "              [ -4.26474512e-02   1.11270808e-01  -2.29757562e-01\n",
      "                -8.58715177e-03  -2.15489015e-01]]]]), bias=variable b([ 0.28911307 -0.61738491  0.38640532 -0.02721917 -0.58936286\n",
      "            -0.634776  ])\n",
      "Epoch 13 loss(train) = variable(26.106876373291016), accuracy(train) = 0.9242, accuracy(test) = 0.9138\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 2 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 3 6 9]\n",
      "1: weight=variable W([[[[  1.19504333e-01   1.67323127e-01   1.68403134e-01\n",
      "                -2.13723499e-02  -4.84838903e-01]\n",
      "              [ -3.52045983e-01  -5.10536075e-01  -6.80892169e-01\n",
      "                -8.87579143e-01  -5.30317962e-01]\n",
      "              [ -3.82787913e-01  -6.23574197e-01  -1.01518261e+00\n",
      "                -8.71681750e-01  -5.53593636e-02]\n",
      "              [ -1.98367178e-01  -6.39779389e-01  -3.75066012e-01\n",
      "                -2.35547759e-02   1.15288951e-01]\n",
      "              [ -2.79311121e-01  -1.95241585e-01  -3.03373665e-01\n",
      "                -2.83043049e-02   9.62514639e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -5.73807895e-01  -3.27529348e-02  -2.08881304e-01\n",
      "                 9.77463648e-03   1.11380659e-01]\n",
      "              [ -3.09997727e-03  -6.17962070e-02   3.73086721e-01\n",
      "                 1.02570879e+00   8.80063593e-01]\n",
      "              [ -5.19754589e-01   2.13254973e-01   7.52314985e-01\n",
      "                 9.88845766e-01   1.16526651e+00]\n",
      "              [ -3.31355870e-01  -1.28217656e-02   6.30384922e-01\n",
      "                 5.34467995e-01   6.83229625e-01]\n",
      "              [ -4.74881411e-01  -2.14055330e-01   1.34672760e-03\n",
      "                 4.91392106e-01   4.10216767e-03]]]\n",
      "\n",
      "\n",
      "            [[[  6.12612665e-01   1.18224904e-01  -2.86427855e-01\n",
      "                -2.06476852e-01  -1.00910389e+00]\n",
      "              [  1.24135971e-01  -1.97772324e-01  -6.36524022e-01\n",
      "                -7.64690638e-01  -1.10377073e+00]\n",
      "              [  4.29025054e-01  -2.08037183e-01  -1.00908804e+00\n",
      "                -9.32560325e-01  -4.44622576e-01]\n",
      "              [ -1.83927678e-02  -1.36115238e-01  -9.97906506e-01\n",
      "                -1.00137365e+00   1.39662802e-01]\n",
      "              [  2.10039780e-01  -1.71544418e-01  -9.12075162e-01\n",
      "                -5.10936022e-01   2.90346537e-02]]]\n",
      "\n",
      "\n",
      "            [[[ -3.28368068e-01  -7.18954861e-01  -1.97064295e-01\n",
      "                -1.79160163e-01   9.27628577e-01]\n",
      "              [ -6.46191835e-01  -1.01221633e+00  -7.75784254e-01\n",
      "                -1.39874503e-01   6.32942200e-01]\n",
      "              [ -9.30954218e-01  -1.22943699e+00  -3.51862133e-01\n",
      "                 6.63379356e-02   6.96378708e-01]\n",
      "              [ -8.33876789e-01  -6.14826918e-01  -5.20089507e-01\n",
      "                 1.03985064e-03   9.52094495e-01]\n",
      "              [ -7.15654075e-01  -6.24073923e-01  -9.60129425e-02\n",
      "                 3.21244895e-01   9.39462125e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -1.11039750e-01  -2.66090706e-02   1.04311310e-01\n",
      "                -3.19420584e-02  -5.29627167e-02]\n",
      "              [  4.54334855e-01   5.22393405e-01   4.97599274e-01\n",
      "                 5.98985136e-01   5.18125296e-01]\n",
      "              [  7.56433129e-01   7.12359250e-01   8.78807962e-01\n",
      "                 7.76675999e-01   6.67291641e-01]\n",
      "              [ -1.49963498e-02   2.87986342e-02   6.79374278e-01\n",
      "                 4.19106662e-01   8.32349136e-02]\n",
      "              [  5.93578629e-02   2.81604439e-01   4.25534658e-02\n",
      "                 9.28284228e-02  -1.59876645e-01]]]\n",
      "\n",
      "\n",
      "            [[[  5.41067049e-02  -1.85964242e-01  -3.85436639e-02\n",
      "                 1.90650731e-01  -1.91388413e-01]\n",
      "              [  5.50929070e-01   3.03123921e-01   5.01525104e-01\n",
      "                 4.24084395e-01   2.86844999e-01]\n",
      "              [  7.50377953e-01   9.33166325e-01   1.11211371e+00\n",
      "                 4.60879445e-01   2.13789999e-01]\n",
      "              [ -1.45980224e-01   7.42135227e-01   1.13493420e-01\n",
      "                 2.16204301e-01   2.20939487e-01]\n",
      "              [ -6.48818687e-02   8.18709061e-02  -2.58058131e-01\n",
      "                -3.65915000e-02  -2.41159305e-01]]]]), bias=variable b([ 0.29867795 -0.61821669  0.38892961 -0.03913711 -0.59386933\n",
      "            -0.64265645])\n",
      "Epoch 14 loss(train) = variable(24.1049747467041), accuracy(train) = 0.9303, accuracy(test) = 0.9211\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 2 9 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 3 6 9]\n",
      "1: weight=variable W([[[[  1.39574721e-01   2.03528300e-01   2.22918883e-01\n",
      "                 2.20193155e-02  -4.61575121e-01]\n",
      "              [ -3.62940520e-01  -5.20045042e-01  -6.80573881e-01\n",
      "                -9.14281785e-01  -5.43026626e-01]\n",
      "              [ -4.02374893e-01  -6.63777411e-01  -1.04923403e+00\n",
      "                -9.01535630e-01  -5.36449477e-02]\n",
      "              [ -1.96574494e-01  -6.39642954e-01  -3.55189830e-01\n",
      "                -4.33940394e-03   1.36945754e-01]\n",
      "              [ -2.51035780e-01  -1.63580537e-01  -2.65379608e-01\n",
      "                 6.30616583e-03   9.90465462e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -5.92875957e-01  -5.02696857e-02  -2.27336794e-01\n",
      "                -9.68462322e-03   9.85961556e-02]\n",
      "              [ -1.36397220e-02  -6.14872910e-02   3.68918180e-01\n",
      "                 1.01669180e+00   8.78666401e-01]\n",
      "              [ -5.19226193e-01   2.28409559e-01   7.63299942e-01\n",
      "                 1.00563085e+00   1.17566776e+00]\n",
      "              [ -3.33931744e-01  -7.65273208e-03   6.28166795e-01\n",
      "                 5.34818292e-01   6.79880679e-01]\n",
      "              [ -4.83865380e-01  -2.18966335e-01  -8.77783168e-03\n",
      "                 4.78757113e-01  -1.46632204e-02]]]\n",
      "\n",
      "\n",
      "            [[[  6.32175863e-01   1.42485350e-01  -2.63568133e-01\n",
      "                -1.89863473e-01  -9.95747387e-01]\n",
      "              [  1.35687381e-01  -1.83484569e-01  -6.33402705e-01\n",
      "                -7.81560183e-01  -1.10027015e+00]\n",
      "              [  4.40739781e-01  -1.93668604e-01  -1.01289725e+00\n",
      "                -9.66788709e-01  -4.36847985e-01]\n",
      "              [  1.14561315e-03  -1.23528443e-01  -1.01403141e+00\n",
      "                -1.01737618e+00   1.53885305e-01]\n",
      "              [  2.30511799e-01  -1.61219433e-01  -9.23626602e-01\n",
      "                -5.12600005e-01   4.87976074e-02]]]\n",
      "\n",
      "\n",
      "            [[[ -3.08854133e-01  -7.06435740e-01  -1.92253217e-01\n",
      "                -1.72129050e-01   9.37603593e-01]\n",
      "              [ -6.41184807e-01  -1.02040148e+00  -7.87066519e-01\n",
      "                -1.45039961e-01   6.37494206e-01]\n",
      "              [ -9.46212471e-01  -1.24832988e+00  -3.65431011e-01\n",
      "                 5.83654791e-02   6.98851287e-01]\n",
      "              [ -8.42466354e-01  -6.18833005e-01  -5.16738832e-01\n",
      "                 4.08967212e-03   9.51665998e-01]\n",
      "              [ -7.14206219e-01  -6.18706048e-01  -8.54621306e-02\n",
      "                 3.28653604e-01   9.42389905e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -1.21312998e-01  -4.00986634e-02   8.89951512e-02\n",
      "                -4.84705083e-02  -6.05042428e-02]\n",
      "              [  4.63025331e-01   5.20786166e-01   4.88413125e-01\n",
      "                 5.97243011e-01   5.28247714e-01]\n",
      "              [  7.69969404e-01   7.20763683e-01   8.96877587e-01\n",
      "                 7.84293056e-01   6.78462684e-01]\n",
      "              [ -2.74172425e-02   1.45358527e-02   6.77547872e-01\n",
      "                 4.16292578e-01   9.16434079e-02]\n",
      "              [  4.26892787e-02   2.66373068e-01   2.85060741e-02\n",
      "                 7.67850131e-02  -1.74745396e-01]]]\n",
      "\n",
      "\n",
      "            [[[  4.14685011e-02  -1.99418858e-01  -4.94914763e-02\n",
      "                 1.75962150e-01  -2.03025103e-01]\n",
      "              [  5.55250943e-01   2.96862721e-01   5.03163755e-01\n",
      "                 4.28593457e-01   2.91220933e-01]\n",
      "              [  7.62331963e-01   9.36327517e-01   1.12748373e+00\n",
      "                 4.67354566e-01   2.21069470e-01]\n",
      "              [ -1.58685640e-01   7.24034488e-01   1.01151042e-01\n",
      "                 2.08924070e-01   2.22053126e-01]\n",
      "              [ -8.47092345e-02   5.43124825e-02  -2.83923298e-01\n",
      "                -6.17155656e-02  -2.62891918e-01]]]]), bias=variable b([ 0.30767569 -0.61898881  0.3910636  -0.0502322  -0.59841537\n",
      "            -0.65022928])\n",
      "Epoch 15 loss(train) = variable(22.40738296508789), accuracy(train) = 0.9359, accuracy(test) = 0.9254\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 2 7 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 3 6 9]\n",
      "1: weight=variable W([[[[  1.58204719e-01   2.37765104e-01   2.76437700e-01\n",
      "                 6.51560798e-02  -4.38410282e-01]\n",
      "              [ -3.74270737e-01  -5.29234111e-01  -6.76752090e-01\n",
      "                -9.37583804e-01  -5.56543708e-01]\n",
      "              [ -4.24354881e-01  -7.06284106e-01  -1.08434176e+00\n",
      "                -9.33221936e-01  -5.59122786e-02]\n",
      "              [ -1.95869446e-01  -6.39758825e-01  -3.37746173e-01\n",
      "                 1.04624592e-02   1.54033154e-01]\n",
      "              [ -2.23560408e-01  -1.33447558e-01  -2.29946703e-01\n",
      "                 3.71786542e-02   1.01493287e+00]]]\n",
      "\n",
      "\n",
      "            [[[ -6.09277189e-01  -6.56431913e-02  -2.44395420e-01\n",
      "                -2.76804026e-02   8.69345367e-02]\n",
      "              [ -2.23732293e-02  -6.07475415e-02   3.64941418e-01\n",
      "                 1.00841701e+00   8.77304435e-01]\n",
      "              [ -5.18304467e-01   2.42896810e-01   7.73524225e-01\n",
      "                 1.01972997e+00   1.18543160e+00]\n",
      "              [ -3.36324930e-01  -2.74808123e-03   6.26119316e-01\n",
      "                 5.34052074e-01   6.76954210e-01]\n",
      "              [ -4.92576182e-01  -2.23684147e-01  -1.86435748e-02\n",
      "                 4.66254652e-01  -3.25492099e-02]]]\n",
      "\n",
      "\n",
      "            [[[  6.50881946e-01   1.65702537e-01  -2.41961569e-01\n",
      "                -1.74165204e-01  -9.81982768e-01]\n",
      "              [  1.46871611e-01  -1.69944569e-01  -6.29403889e-01\n",
      "                -7.97360837e-01  -1.09489989e+00]\n",
      "              [  4.50552911e-01  -1.81026056e-01  -1.01551104e+00\n",
      "                -1.00008237e+00  -4.29554731e-01]\n",
      "              [  1.88727025e-02  -1.12521194e-01  -1.02893329e+00\n",
      "                -1.03375089e+00   1.66098699e-01]\n",
      "              [  2.49121010e-01  -1.51272863e-01  -9.33958769e-01\n",
      "                -5.14852762e-01   6.58430234e-02]]]\n",
      "\n",
      "\n",
      "            [[[ -2.90839732e-01  -6.94989443e-01  -1.87635809e-01\n",
      "                -1.65004909e-01   9.47198987e-01]\n",
      "              [ -6.34514093e-01  -1.02654743e+00  -7.97332287e-01\n",
      "                -1.50069252e-01   6.41679585e-01]\n",
      "              [ -9.58349407e-01  -1.26555562e+00  -3.78522545e-01\n",
      "                 5.05480804e-02   7.00671196e-01]\n",
      "              [ -8.50182295e-01  -6.23146951e-01  -5.14397860e-01\n",
      "                 5.87093364e-03   9.50033844e-01]\n",
      "              [ -7.13429511e-01  -6.15171850e-01  -7.68670067e-02\n",
      "                 3.34308565e-01   9.43910420e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -1.30010962e-01  -5.10612056e-02   7.68353790e-02\n",
      "                -6.30047545e-02  -6.75535277e-02]\n",
      "              [  4.71496373e-01   5.19778788e-01   4.80302900e-01\n",
      "                 5.95592856e-01   5.37799656e-01]\n",
      "              [  7.82876492e-01   7.27810442e-01   9.13186669e-01\n",
      "                 7.91319549e-01   6.90210879e-01]\n",
      "              [ -3.83099467e-02   8.87081784e-04   6.74704373e-01\n",
      "                 4.13495570e-01   1.00741424e-01]\n",
      "              [  2.80015711e-02   2.52045125e-01   1.49791706e-02\n",
      "                 6.13028929e-02  -1.88004121e-01]]]\n",
      "\n",
      "\n",
      "            [[[  3.02935243e-02  -2.10303888e-01  -5.69423735e-02\n",
      "                 1.64537609e-01  -2.12730750e-01]\n",
      "              [  5.59450567e-01   2.91619599e-01   5.06828904e-01\n",
      "                 4.33644146e-01   2.95733690e-01]\n",
      "              [  7.73673475e-01   9.37960923e-01   1.14190972e+00\n",
      "                 4.73824620e-01   2.28482038e-01]\n",
      "              [ -1.68461606e-01   7.07847059e-01   9.02134851e-02\n",
      "                 2.01582298e-01   2.23284528e-01]\n",
      "              [ -1.01440385e-01   2.90454458e-02  -3.07783633e-01\n",
      "                -8.50609243e-02  -2.82441556e-01]]]]), bias=variable b([ 0.31579703 -0.61981696  0.39285317 -0.06050424 -0.60308641\n",
      "            -0.6575942 ])\n",
      "Epoch 16 loss(train) = variable(20.928617477416992), accuracy(train) = 0.9401, accuracy(test) = 0.9299\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 2 7 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 3 6 9]\n",
      "1: weight=variable W([[[[ 0.17442462  0.26853687  0.32590523  0.10529516 -0.41610923]\n",
      "              [-0.38602591 -0.53857797 -0.67106694 -0.95931768 -0.57105434]\n",
      "              [-0.44789681 -0.75045574 -1.11980057 -0.96585625 -0.06141971]\n",
      "              [-0.19612904 -0.63994002 -0.32202381  0.02195466  0.1665667 ]\n",
      "              [-0.19755626 -0.10579669 -0.19861983  0.06380949  1.03564572]]]\n",
      "\n",
      "\n",
      "            [[[-0.62402636 -0.07964634 -0.26007742 -0.04393446  0.07616237]\n",
      "              [-0.02927325 -0.05933647  0.36160561  1.0008558   0.87604117]\n",
      "              [-0.51645654  0.25706676  0.78337896  1.03165996  1.19491279]\n",
      "              [-0.33840913  0.00204778  0.62465036  0.53217375  0.67443299]\n",
      "              [-0.50090408 -0.22803159 -0.02782501  0.45415732 -0.04962814]]]\n",
      "\n",
      "\n",
      "            [[[ 0.66892606  0.18824609 -0.22229397 -0.16017991 -0.96813637]\n",
      "              [ 0.15740997 -0.15714115 -0.62488145 -0.81209314 -1.08713722]\n",
      "              [ 0.45921144 -0.16938351 -1.01745784 -1.03202522 -0.42217156]\n",
      "              [ 0.03474708 -0.10172161 -1.0424453  -1.05001485  0.17659809]\n",
      "              [ 0.26621357 -0.1415167  -0.94304401 -0.51770157  0.0801936 ]]]\n",
      "\n",
      "\n",
      "            [[[-0.27359077 -0.68463451 -0.18278521 -0.15741399  0.95686501]\n",
      "              [-0.62601393 -1.03046286 -0.80642349 -0.15477815  0.64553118]\n",
      "              [-0.96763539 -1.28088033 -0.39145675  0.0423933   0.70177102]\n",
      "              [-0.85686636 -0.62802875 -0.51311982  0.00656733  0.94772118]\n",
      "              [-0.71331674 -0.61303616 -0.06996404  0.33873767  0.94463176]]]\n",
      "\n",
      "\n",
      "            [[[-0.13755734 -0.0603588   0.06753156 -0.07548814 -0.07379774]\n",
      "              [ 0.47957441  0.51921439  0.47351566  0.5937472   0.54694307]\n",
      "              [ 0.79565132  0.73368013  0.92817307  0.79706985  0.70201617]\n",
      "              [-0.04753359 -0.01202354  0.67185515  0.41086894  0.1097948 ]\n",
      "              [ 0.01546657  0.23924403  0.00326017  0.04718296 -0.19969937]]]\n",
      "\n",
      "\n",
      "            [[[ 0.02139578 -0.21910304 -0.06101388  0.15585296 -0.22107483]\n",
      "              [ 0.56461763  0.28815985  0.51204938  0.43901235  0.29962534]\n",
      "              [ 0.78457803  0.93806469  1.15573525  0.48018411  0.23558567]\n",
      "              [-0.17802107  0.69177598  0.07943395  0.19467577  0.22444873]\n",
      "              [-0.11753321  0.00498635 -0.32970455 -0.10670024 -0.30023101]]]]), bias=variable b([ 0.32294989 -0.62072933  0.39436695 -0.06994024 -0.60784996\n",
      "            -0.66480368])\n",
      "Epoch 17 loss(train) = variable(19.607301712036133), accuracy(train) = 0.9436, accuracy(test) = 0.9328\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 2 7 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 3 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "1: weight=variable W([[[[ 0.18833785  0.29516914  0.37005654  0.14214072 -0.39488029]\n",
      "              [-0.39887309 -0.54905772 -0.66505408 -0.97857159 -0.58494312]\n",
      "              [-0.47236764 -0.7945593  -1.15441132 -0.99835432 -0.06907698]\n",
      "              [-0.19741549 -0.64003009 -0.30838802  0.02952624  0.1753877 ]\n",
      "              [-0.17430338 -0.08035688 -0.1703576   0.08709455  1.05326903]]]\n",
      "\n",
      "\n",
      "            [[[-0.63743293 -0.09224892 -0.27471888 -0.05936821  0.06560446]\n",
      "              [-0.03542725 -0.05765521  0.3583231   0.99393004  0.87506366]\n",
      "              [-0.51346701  0.27151603  0.79326952  1.0416261   1.20394897]\n",
      "              [-0.34027827  0.00667824  0.62345266  0.52968854  0.67241323]\n",
      "              [-0.50904137 -0.23181154 -0.03589905  0.44295335 -0.06497125]]]\n",
      "\n",
      "\n",
      "            [[[ 0.68595862  0.21005765 -0.20345856 -0.14738142 -0.95407379]\n",
      "              [ 0.16725783 -0.14441559 -0.62009799 -0.82608932 -1.07717037]\n",
      "              [ 0.46656933 -0.15820973 -1.01911199 -1.06302488 -0.41489744]\n",
      "              [ 0.04861562 -0.09216543 -1.05526984 -1.06658745  0.18537717]\n",
      "              [ 0.28164637 -0.1328129  -0.95193022 -0.52121776  0.09214018]]]\n",
      "\n",
      "\n",
      "            [[[-0.25768766 -0.67536074 -0.1778122  -0.14952411  0.96628195]\n",
      "              [-0.61689436 -1.03277183 -0.81406271 -0.15857206  0.64917773]\n",
      "              [-0.97548884 -1.29462326 -0.40379232  0.03419204  0.70248926]\n",
      "              [-0.86163342 -0.6324634  -0.51213408  0.00677246  0.94504666]\n",
      "              [-0.71313542 -0.61190039 -0.0642368   0.3423923   0.94499898]]]\n",
      "\n",
      "\n",
      "            [[[-0.14347607 -0.06798823  0.060398   -0.08626001 -0.07964182]\n",
      "              [ 0.48764005  0.51850516  0.4680526   0.59249383  0.55530787]\n",
      "              [ 0.80773848  0.73777097  0.94180363  0.80240482  0.7137723 ]\n",
      "              [-0.05699384 -0.02424781  0.66934317  0.4083893   0.11918388]\n",
      "              [ 0.00315055  0.22732933 -0.00752043  0.0338564  -0.21034244]]]\n",
      "\n",
      "\n",
      "            [[[ 0.01338406 -0.22676797 -0.06276648  0.14921331 -0.22844878]\n",
      "              [ 0.56962949  0.28598201  0.51828319  0.44403866  0.30284393]\n",
      "              [ 0.79483438  0.93753481  1.16892993  0.48596305  0.24187414]\n",
      "              [-0.18682398  0.67667335  0.07002359  0.18752867  0.22476807]\n",
      "              [-0.13320276 -0.018545   -0.35056946 -0.12726788 -0.31641993]]]]), bias=variable b([ 0.3291893  -0.62187278  0.39560291 -0.07852153 -0.61288464\n",
      "            -0.67206049])\n",
      "Epoch 18 loss(train) = variable(18.40949821472168), accuracy(train) = 0.9471, accuracy(test) = 0.936\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 2 7 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "1: weight=variable W([[[[ 0.20015676  0.31825528  0.41040561  0.17672843 -0.37519187]\n",
      "              [-0.41192052 -0.55926192 -0.6576075  -0.99469411 -0.59808266]\n",
      "              [-0.49708837 -0.83668572 -1.18787181 -1.02958798 -0.07812225]\n",
      "              [-0.19924079 -0.6413542  -0.29669696  0.03458899  0.18138281]\n",
      "              [-0.15243633 -0.05729586 -0.14543134  0.10701174  1.06824362]]]\n",
      "\n",
      "\n",
      "            [[[-0.64981639 -0.10395405 -0.288385   -0.07353141  0.05615715]\n",
      "              [-0.04049039 -0.05565461  0.35521433  0.98734862  0.87423927]\n",
      "              [-0.51006532  0.28562903  0.8026489   1.04993856  1.21288586]\n",
      "              [-0.342197    0.01106825  0.62261224  0.52719605  0.67121822]\n",
      "              [-0.51617074 -0.23490332 -0.04306327  0.43238005 -0.07932927]]]\n",
      "\n",
      "\n",
      "            [[[ 0.70209056  0.23108009 -0.18532601 -0.13564247 -0.93936968]\n",
      "              [ 0.17677553 -0.13225123 -0.61447829 -0.83815396 -1.06501675]\n",
      "              [ 0.47291636 -0.14760299 -1.02050984 -1.09340405 -0.4077639 ]\n",
      "              [ 0.06048179 -0.08396923 -1.06768084 -1.08340406  0.19257478]\n",
      "              [ 0.29546222 -0.12556821 -0.96062034 -0.52565902  0.10203748]]]\n",
      "\n",
      "\n",
      "            [[[-0.24267742 -0.6661703  -0.17222945 -0.14080526  0.97572368]\n",
      "              [-0.60732347 -1.0334121  -0.82005799 -0.16137715  0.65284204]\n",
      "              [-0.98200059 -1.30730426 -0.41526437  0.02620061  0.70301801]\n",
      "              [-0.86545122 -0.63696283 -0.51170993  0.00640416  0.94222426]\n",
      "              [-0.71355098 -0.61197215 -0.05970245  0.34534442  0.94502121]]]\n",
      "\n",
      "\n",
      "            [[[-0.14852472 -0.07436434  0.05538471 -0.09548511 -0.08540442]\n",
      "              [ 0.4958092   0.51860368  0.46345654  0.59060913  0.56247717]\n",
      "              [ 0.81963903  0.74119925  0.95402163  0.80673826  0.72528738]\n",
      "              [-0.06613118 -0.03660999  0.6671055   0.40594611  0.12844078]\n",
      "              [-0.00762318  0.2157881  -0.0178994   0.02080524 -0.22059584]]]\n",
      "\n",
      "\n",
      "            [[[ 0.00630084 -0.23352207 -0.06296163  0.14459451 -0.2351944 ]\n",
      "              [ 0.57382309  0.2848281   0.52547634  0.44929275  0.30508801]\n",
      "              [ 0.80398339  0.93645281  1.1818192   0.49141842  0.24771433]\n",
      "              [-0.19502252  0.66327733  0.06248685  0.18200682  0.22563227]\n",
      "              [-0.14748128 -0.03978226 -0.36836949 -0.14505562 -0.3315542 ]]]]), bias=variable b([ 0.334609   -0.62315524  0.39660314 -0.08634795 -0.6180743\n",
      "            -0.67932504])\n",
      "Epoch 19 loss(train) = variable(17.314207077026367), accuracy(train) = 0.9499, accuracy(test) = 0.94\n",
      "[ 5.  0.  4.  1.  9.  2.  1.  3.  1.  4.  3.  5.  3.  6.  1.  7.  2.  8.\n",
      "  6.  9.  4.  0.  9.  1.  1.  2.  4.  3.  2.  7.  3.  8.  6.  9.  0.  5.\n",
      "  6.  0.  7.  6.  1.  8.  7.  9.  3.  9.  8.  5.  9.  3.  3.  0.  7.  4.\n",
      "  9.  8.  0.  9.  4.  1.  4.  4.  6.  0.  4.  5.  6.  1.  0.  0.  1.  7.\n",
      "  1.  6.  3.  0.  2.  1.  1.  7.  9.  0.  2.  6.  7.  8.  3.  9.  0.  4.\n",
      "  6.  7.  4.  6.  8.  0.  7.  8.  3.  1.]\n",
      "[3 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 2 2 4 3 2 7 3 8 6 7 0 5 6\n",
      " 0 7 6 1 8 7 9 3 9 8 5 5 3 3 0 7 4 9 8 0 9 4 1 4 4 6 0 4 5 6 1 0 0 2 7 1 6\n",
      " 3 0 2 1 1 7 0 0 2 6 7 8 3 9 0 4 6 7 4 6 8 0 7 8 3 1]\n",
      "[ 7.  2.  1.  0.  4.  1.  4.  9.  5.  9.  0.  6.  9.  0.  1.  5.  9.  7.\n",
      "  3.  4.  9.  6.  6.  5.  4.  0.  7.  4.  0.  1.  3.  1.  3.  4.  7.  2.\n",
      "  7.  1.  2.  1.  1.  7.  4.  2.  3.  5.  1.  2.  4.  4.  6.  3.  5.  5.\n",
      "  6.  0.  4.  1.  9.  5.  7.  8.  9.  3.  7.  4.  6.  4.  3.  0.  7.  0.\n",
      "  2.  9.  1.  7.  3.  2.  9.  7.  7.  6.  2.  7.  8.  4.  7.  3.  6.  1.\n",
      "  3.  6.  9.  3.  1.  4.  1.  7.  6.  9.]\n",
      "[7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1 3 1 3 6 7 2 7\n",
      " 1 2 1 1 7 4 2 3 5 1 2 4 4 6 3 5 5 6 0 4 1 9 5 7 8 9 3 7 9 6 4 3 0 7 0 2 8\n",
      " 1 7 3 2 9 7 9 6 2 7 8 4 7 3 6 1 3 6 9 3 1 4 1 7 6 9]\n",
      "1: weight=variable W([[[[  2.10612908e-01   3.38118583e-01   4.46373433e-01\n",
      "                 2.08115041e-01  -3.56910169e-01]\n",
      "              [ -4.24850047e-01  -5.69811404e-01  -6.51240766e-01\n",
      "                -1.00927520e+00  -6.10672355e-01]\n",
      "              [ -5.21338701e-01  -8.76525700e-01  -1.22003841e+00\n",
      "                -1.06039345e+00  -8.86709541e-02]\n",
      "              [ -2.01871157e-01  -6.42589331e-01  -2.86515981e-01\n",
      "                 3.70741598e-02   1.84439927e-01]\n",
      "              [ -1.31884038e-01  -3.60211544e-02  -1.23065390e-01\n",
      "                 1.24186918e-01   1.08063889e+00]]]\n",
      "\n",
      "\n",
      "            [[[ -6.60660446e-01  -1.14466339e-01  -3.01149458e-01\n",
      "                -8.69338289e-02   4.72478941e-02]\n",
      "              [ -4.42491211e-02  -5.33728972e-02   3.52214724e-01\n",
      "                 9.81303453e-01   8.74010026e-01]\n",
      "              [ -5.06668091e-01   2.98690170e-01   8.11282516e-01\n",
      "                 1.05719793e+00   1.22191298e+00]\n",
      "              [ -3.44521463e-01   1.48226209e-02   6.21791363e-01\n",
      "                 5.24315655e-01   6.70802176e-01]\n",
      "              [ -5.23203909e-01  -2.37684995e-01  -4.97392751e-02\n",
      "                 4.22328174e-01  -9.26858783e-02]]]\n",
      "\n",
      "\n",
      "            [[[  7.17295945e-01   2.51260221e-01  -1.68233603e-01\n",
      "                -1.24602012e-01  -9.24123228e-01]\n",
      "              [  1.86001286e-01  -1.20285802e-01  -6.07994318e-01\n",
      "                -8.48763824e-01  -1.05136800e+00]\n",
      "              [  4.79171515e-01  -1.37226328e-01  -1.02115309e+00\n",
      "                -1.12329268e+00  -4.01278585e-01]\n",
      "              [  7.09584877e-02  -7.60903358e-02  -1.07895148e+00\n",
      "                -1.10073698e+00   1.97727486e-01]\n",
      "              [  3.08148980e-01  -1.18732750e-01  -9.68646407e-01\n",
      "                -5.30600905e-01   1.10341564e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -2.28127167e-01  -6.57180190e-01  -1.66168362e-01\n",
      "                -1.31464809e-01   9.85376596e-01]\n",
      "              [ -5.97115934e-01  -1.03248894e+00  -8.24676037e-01\n",
      "                -1.63420320e-01   6.56500757e-01]\n",
      "              [ -9.86684203e-01  -1.31887424e+00  -4.26118284e-01\n",
      "                 1.83919426e-02   7.03408122e-01]\n",
      "              [ -8.68171513e-01  -6.41873479e-01  -5.11985958e-01\n",
      "                 5.70378732e-03   9.39360440e-01]\n",
      "              [ -7.14106083e-01  -6.12868249e-01  -5.61653934e-02\n",
      "                 3.47684801e-01   9.44738328e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -1.52778089e-01  -7.99145699e-02   5.20239212e-02\n",
      "                -1.03249997e-01  -9.02507901e-02]\n",
      "              [  5.03291309e-01   5.18958628e-01   4.60372955e-01\n",
      "                 5.88812709e-01   5.69182038e-01]\n",
      "              [  8.30486715e-01   7.44082868e-01   9.65583920e-01\n",
      "                 8.10618341e-01   7.36817002e-01]\n",
      "              [ -7.48869181e-02  -4.87250425e-02   6.65064454e-01\n",
      "                 4.03904468e-01   1.37940869e-01]\n",
      "              [ -1.72297973e-02   2.05609098e-01  -2.69736908e-02\n",
      "                 9.02525149e-03  -2.29513988e-01]]]\n",
      "\n",
      "\n",
      "            [[[ -7.33495457e-04  -2.40226582e-01  -6.28262907e-02\n",
      "                 1.40737548e-01  -2.41701990e-01]\n",
      "              [  5.77648520e-01   2.83971190e-01   5.32754600e-01\n",
      "                 4.54222769e-01   3.06809455e-01]\n",
      "              [  8.12536180e-01   9.34933901e-01   1.19442689e+00\n",
      "                 4.97044861e-01   2.53464282e-01]\n",
      "              [ -2.02477276e-01   6.51059568e-01   5.61800078e-02\n",
      "                 1.77139401e-01   2.26257086e-01]\n",
      "              [ -1.60706475e-01  -5.94117045e-02  -3.84111106e-01\n",
      "                -1.61342546e-01  -3.45907152e-01]]]]), bias=variable b([ 0.33920699 -0.62449092  0.39738324 -0.09349673 -0.6233328\n",
      "            -0.68649882])\n",
      "Epoch 20 loss(train) = variable(16.308006286621094), accuracy(train) = 0.9533, accuracy(test) = 0.9429\n"
     ]
    }
   ],
   "source": [
    "# learn\n",
    "\n",
    "model = LeNet(10)\n",
    "#optimizer = optimizers.SGD()\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "batchsize = 100\n",
    "datasize = len(xs)\n",
    "\n",
    "# use GPU\n",
    "#chainer.cuda.get_device_from_id(0).use()\n",
    "#model.to_gpu()\n",
    "\n",
    "#xp = cuda.cupy\n",
    "\n",
    "for epoch in range(20):\n",
    "    for i in range(0, datasize, batchsize):\n",
    "        x = xs[i:i + batchsize]\n",
    "        t = ts[i:i + batchsize]\n",
    "        \n",
    "        #var_x = Variable(cuda.to_gpu(x))\n",
    "        var_x = Variable(x)\n",
    "        t = Variable(np.array(t, \"i\"))\n",
    "        y = model(var_x)\n",
    "        \n",
    "        model.cleargrads()\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "    accuracy_train, loss_train = check_accuracy(model, xs, ts, batchsize)\n",
    "    accuracy_test, _           = check_accuracy(model, txs, tts, batchsize)\n",
    "    \n",
    "    optimizer.new_epoch()\n",
    "    \n",
    "    print(\"1: weight={0}, bias={1}\".format(model.conv1.W, model.conv1.b))\n",
    "    print(\"Epoch {0} loss(train) = {1}, accuracy(train) = {2}, accuracy(test) = {3}\".format(epoch + 1, loss_train, accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
