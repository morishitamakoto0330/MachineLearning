{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LeNet Class\n",
    "\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers\n",
    "from chainer import Variable\n",
    "from chainer import cuda\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class LeNet(chainer.Chain):\n",
    "    def __init__(self, num_class, train=True):\n",
    "        super(LeNet, self).__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1=L.Convolution2D(None, 6, 5, stride=1)\n",
    "            self.conv2=L.Convolution2D(None, 16, 5, stride=1)\n",
    "            self.conv3=L.Convolution2D(None, 120, 5, stride=1)\n",
    "            self.fc4=L.Linear(None, 84)\n",
    "            self.fc5=L.Linear(None, num_class)\n",
    "            \n",
    "    def __call__(self, x):\n",
    "        h1 = F.max_pooling_2d(F.local_response_normalization(\n",
    "            F.sigmoid(self.conv1(x))), 2, stride=2)\n",
    "        h2 = F.max_pooling_2d(F.local_response_normalization(\n",
    "            F.sigmoid(self.conv2(h1))), 2, stride=2)\n",
    "        h3 = F.sigmoid(self.conv3(h2))\n",
    "        h4 = F.sigmoid(self.fc4(h3))\n",
    "        h5 = self.fc5(h4)\n",
    "        \n",
    "        return h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MNIST data set\n",
    "\n",
    "train, test = chainer.datasets.get_mnist()\n",
    "_xs, ts = train._datasets\n",
    "_txs, tts = test._datasets\n",
    "\n",
    "size = 10000\n",
    "_xs = _xs[:size]\n",
    "ts = ts[:size]\n",
    "_txs = _txs[:size]\n",
    "tts = tts[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# padding (60000, 784) -> (60000, 1, 28, 28) -> (60000, 1, 32, 32)\n",
    "\n",
    "_v0 = np.row_stack((np.zeros(28), np.zeros(28)))\n",
    "v0 = np.array(_v0)\n",
    "_h0 = np.column_stack((np.zeros(32), np.zeros(32)))\n",
    "h0 = np.array(_h0)\n",
    "\n",
    "def padding(x):\n",
    "    tmp1 = np.vstack((x, v0))\n",
    "    tmp2 = np.vstack((v0, tmp1))\n",
    "    _tmp1 = np.hstack((tmp2, h0))\n",
    "    _tmp2 = np.hstack((h0, _tmp1))\n",
    "    return _tmp2\n",
    "\n",
    "xs_list = []\n",
    "for i in range(len(_xs)):\n",
    "    x = np.reshape(_xs[i], (28, 28))\n",
    "    pad_x = padding(x)\n",
    "    xs_list.append(pad_x[np.newaxis, :, :])\n",
    "txs_list = []\n",
    "for i in range(len(_txs)):\n",
    "    tx = np.reshape(_txs[i], (28, 28))\n",
    "    pad_tx = padding(tx)\n",
    "    txs_list.append(pad_tx[np.newaxis, :, :])\n",
    "    \n",
    "xs = np.array(xs_list, dtype=np.float32)\n",
    "txs = np.array(txs_list, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# method\n",
    "\n",
    "def check_accuracy(model, xs, ts, batchsize):\n",
    "    loss = 0\n",
    "    num_cors = 0\n",
    "    for i in range(0, len(xs), batchsize):\n",
    "        x = xs[i:i + batchsize]\n",
    "        t = ts[i:i + batchsize]\n",
    "        \n",
    "        #var_xs = Variable(cuda.to_gpu(x))\n",
    "        var_xs = Variable(x)\n",
    "        t = Variable(np.array(t, \"i\"))\n",
    "        ys = model(var_xs)\n",
    "    \n",
    "        loss += F.softmax_cross_entropy(ys, t)\n",
    "        ys = np.argmax(ys.data, axis=1)\n",
    "        #_t = cuda.to_gpu(np.array(cuda.to_cpu(t.data), dtype=np.float32))\n",
    "        _t = np.array(t.data, dtype=np.float32)\n",
    "        cors = (ys == _t)\n",
    "        num_cors += sum(cors)\n",
    "    accuracy = num_cors / ts.shape[0]\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss(train) = variable(230.28713989257812), accuracy(train) = 0.1032, accuracy(test) = 0.101\n",
      "Epoch 2 loss(train) = variable(222.10202026367188), accuracy(train) = 0.2127, accuracy(test) = 0.2081\n",
      "Epoch 3 loss(train) = variable(132.77142333984375), accuracy(train) = 0.6389, accuracy(test) = 0.6326\n",
      "Epoch 4 loss(train) = variable(79.36204528808594), accuracy(train) = 0.8043, accuracy(test) = 0.7945\n",
      "Epoch 5 loss(train) = variable(58.37394332885742), accuracy(train) = 0.8507, accuracy(test) = 0.8493\n",
      "Epoch 6 loss(train) = variable(45.74210739135742), accuracy(train) = 0.8811, accuracy(test) = 0.8761\n",
      "Epoch 7 loss(train) = variable(37.34764862060547), accuracy(train) = 0.8993, accuracy(test) = 0.8951\n",
      "Epoch 8 loss(train) = variable(31.24097442626953), accuracy(train) = 0.9159, accuracy(test) = 0.9094\n",
      "Epoch 9 loss(train) = variable(26.801042556762695), accuracy(train) = 0.9265, accuracy(test) = 0.9211\n",
      "Epoch 10 loss(train) = variable(23.549760818481445), accuracy(train) = 0.9372, accuracy(test) = 0.9283\n",
      "Epoch 11 loss(train) = variable(21.08759880065918), accuracy(train) = 0.9447, accuracy(test) = 0.9333\n",
      "Epoch 12 loss(train) = variable(19.150196075439453), accuracy(train) = 0.9479, accuracy(test) = 0.9376\n",
      "Epoch 13 loss(train) = variable(17.56783103942871), accuracy(train) = 0.952, accuracy(test) = 0.9423\n",
      "Epoch 14 loss(train) = variable(16.23311996459961), accuracy(train) = 0.9563, accuracy(test) = 0.9459\n",
      "Epoch 15 loss(train) = variable(15.090274810791016), accuracy(train) = 0.9586, accuracy(test) = 0.9503\n",
      "Epoch 16 loss(train) = variable(14.098326683044434), accuracy(train) = 0.9612, accuracy(test) = 0.9526\n",
      "Epoch 17 loss(train) = variable(13.229413986206055), accuracy(train) = 0.9633, accuracy(test) = 0.9552\n",
      "Epoch 18 loss(train) = variable(12.46430778503418), accuracy(train) = 0.9643, accuracy(test) = 0.9569\n",
      "Epoch 19 loss(train) = variable(11.784590721130371), accuracy(train) = 0.9657, accuracy(test) = 0.9588\n",
      "Epoch 20 loss(train) = variable(11.171549797058105), accuracy(train) = 0.9671, accuracy(test) = 0.9598\n"
     ]
    }
   ],
   "source": [
    "# learn\n",
    "\n",
    "model = LeNet(10)\n",
    "#optimizer = optimizers.SGD()\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "batchsize = 100\n",
    "datasize = len(xs)\n",
    "\n",
    "# use GPU\n",
    "#chainer.cuda.get_device_from_id(0).use()\n",
    "#model.to_gpu()\n",
    "\n",
    "#xp = cuda.cupy\n",
    "\n",
    "for epoch in range(20):\n",
    "    for i in range(0, datasize, batchsize):\n",
    "        x = xs[i:i + batchsize]\n",
    "        t = ts[i:i + batchsize]\n",
    "        \n",
    "        #var_x = Variable(cuda.to_gpu(x))\n",
    "        var_x = Variable(x)\n",
    "        t = Variable(np.array(t, \"i\"))\n",
    "        y = model(var_x)\n",
    "        \n",
    "        model.cleargrads()\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "    accuracy_train, loss_train = check_accuracy(model, xs, ts, batchsize)\n",
    "    accuracy_test, _           = check_accuracy(model, txs, tts, batchsize)\n",
    "    \n",
    "    optimizer.new_epoch()\n",
    "    \n",
    "    #print(\"1: weight={0}, bias={1}\".format(model.conv1.W, model.conv1.b))\n",
    "    print(\"Epoch {0} loss(train) = {1}, accuracy(train) = {2}, accuracy(test) = {3}\".format(epoch + 1, loss_train, accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
